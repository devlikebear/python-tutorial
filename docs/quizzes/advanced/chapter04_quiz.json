{
    "chapter": 4,
    "title": "동시성과 병렬성 심화",
    "total_questions": 25,
    "questions": [
        {
            "id": 1,
            "type": "multiple_choice",
            "difficulty": "basic",
            "question": "ReadWriteLock에서 여러 스레드가 동시에 읽기 락을 획득할 수 있는 이유는 무엇인가요?",
            "options": [
                "읽기 작업은 데이터를 변경하지 않기 때문",
                "읽기 락은 뮤텍스와 동일하기 때문",
                "스레드 풀에서 자동으로 관리하기 때문",
                "쓰기 락보다 우선순위가 높기 때문"
            ],
            "correct": 0,
            "explanation": "읽기 작업은 데이터를 변경하지 않으므로 여러 스레드가 동시에 읽기 락을 안전하게 획득할 수 있습니다."
        },
        {
            "id": 2,
            "type": "multiple_choice",
            "difficulty": "basic",
            "question": "Barrier의 주요 목적은 무엇인가요?",
            "options": [
                "스레드 간 메시지 전달",
                "모든 스레드가 특정 지점에 도달할 때까지 동기화",
                "메모리 공유 관리",
                "데드락 방지"
            ],
            "correct": 1,
            "explanation": "Barrier는 모든 스레드가 특정 지점(장벽)에 도달할 때까지 대기하여 동기화하는 동기화 프리미티브입니다."
        },
        {
            "id": 3,
            "type": "multiple_choice",
            "difficulty": "basic",
            "question": "CountDownLatch의 특징으로 옳은 것은?",
            "options": [
                "카운트를 증가시킬 수 있다",
                "카운트가 0이 되면 재사용할 수 있다",
                "카운트는 감소만 가능하고 0이 되면 대기 중인 스레드들이 해제된다",
                "여러 번 wait를 호출할 수 없다"
            ],
            "correct": 2,
            "explanation": "CountDownLatch는 카운트를 감소시키기만 하며, 0이 되면 대기 중인 모든 스레드들이 해제됩니다."
        },
        {
            "id": 4,
            "type": "multiple_choice",
            "difficulty": "basic",
            "question": "우선순위 스레드 풀에서 작업 할당 순서는 무엇을 기준으로 결정되나요?",
            "options": [
                "제출 순서",
                "스레드 ID",
                "우선순위, 그 다음 생성 시간",
                "작업 크기"
            ],
            "correct": 2,
            "explanation": "우선순위 스레드 풀에서는 먼저 우선순위를 비교하고, 같은 우선순위인 경우 생성 시간(FIFO)으로 순서를 결정합니다."
        },
        {
            "id": 5,
            "type": "multiple_choice",
            "difficulty": "basic",
            "question": "적응형 스레드 풀의 스케일 업 조건은?",
            "options": [
                "메모리 사용량이 증가할 때",
                "대기 중인 작업 수가 현재 워커 수보다 많을 때",
                "CPU 사용률이 높을 때",
                "작업 완료 시간이 길어질 때"
            ],
            "correct": 1,
            "explanation": "적응형 스레드 풀은 대기 중인 작업 수가 현재 워커 수의 일정 배수를 초과하면 워커 수를 증가시킵니다."
        },
        {
            "id": 6,
            "type": "multiple_choice",
            "difficulty": "basic",
            "question": "AsyncIO에서 서킷 브레이커의 OPEN 상태는 언제 발생하나요?",
            "options": [
                "첫 번째 실패가 발생했을 때",
                "실패 횟수가 임계값을 초과했을 때",
                "타임아웃이 발생했을 때",
                "메모리 부족이 발생했을 때"
            ],
            "correct": 1,
            "explanation": "서킷 브레이커는 연속된 실패 횟수가 설정된 임계값을 초과하면 OPEN 상태로 전환됩니다."
        },
        {
            "id": 7,
            "type": "multiple_choice",
            "difficulty": "intermediate",
            "question": "비동기 리소스 풀에서 백프레셔(backpressure) 처리의 목적은?",
            "options": [
                "메모리 사용량 최소화",
                "리소스 생성 속도 제한",
                "시스템 과부하 방지 및 안정성 확보",
                "응답 시간 단축"
            ],
            "correct": 2,
            "explanation": "백프레셔는 시스템이 처리할 수 있는 용량을 초과하는 요청으로부터 시스템을 보호하여 안정성을 확보합니다."
        },
        {
            "id": 8,
            "type": "multiple_choice",
            "difficulty": "intermediate",
            "question": "AsyncBatcher에서 플러시(flush)가 발생하는 조건이 아닌 것은?",
            "options": [
                "배치 크기가 최대값에 도달했을 때",
                "일정 시간 간격마다",
                "시스템 종료 시",
                "메모리 사용량이 임계값을 초과했을 때"
            ],
            "correct": 3,
            "explanation": "AsyncBatcher는 배치 크기, 시간 간격, 시스템 종료 시 플러시하지만, 메모리 사용량은 직접적인 플러시 조건이 아닙니다."
        },
        {
            "id": 9,
            "type": "multiple_choice",
            "difficulty": "intermediate",
            "question": "비동기 재시도 데코레이터에서 백오프(backoff) 전략의 이점은?",
            "options": [
                "메모리 사용량 감소",
                "일시적 장애에 대한 복구 시간 제공",
                "CPU 사용률 향상",
                "코드 복잡도 감소"
            ],
            "correct": 1,
            "explanation": "백오프 전략은 재시도 간격을 점진적으로 늘려서 일시적 장애가 복구될 시간을 제공합니다."
        },
        {
            "id": 10,
            "type": "multiple_choice",
            "difficulty": "intermediate",
            "question": "AsyncStreamProcessor에서 버퍼링의 주요 목적은?",
            "options": [
                "메모리 절약",
                "처리 효율성 향상을 위한 배치 처리",
                "오류 처리 간소화",
                "코드 가독성 향상"
            ],
            "correct": 1,
            "explanation": "버퍼링을 통해 여러 항목을 모아서 배치로 처리하면 개별 처리보다 효율적입니다."
        },
        {
            "id": 11,
            "type": "multiple_choice",
            "difficulty": "intermediate",
            "question": "멀티프로세싱에서 SharedCounter가 필요한 이유는?",
            "options": [
                "프로세스 간 안전한 카운터 공유",
                "메모리 사용량 최적화",
                "처리 속도 향상",
                "코드 단순화"
            ],
            "correct": 0,
            "explanation": "프로세스 간에는 메모리가 격리되어 있으므로, 안전한 카운터 공유를 위해 SharedCounter가 필요합니다."
        },
        {
            "id": 12,
            "type": "multiple_choice",
            "difficulty": "intermediate",
            "question": "분산 데이터 처리에서 청크(chunk) 분할의 이점은?",
            "options": [
                "메모리 사용량 감소",
                "병렬 처리를 통한 성능 향상",
                "오류 처리 간소화",
                "코드 복잡도 감소"
            ],
            "correct": 1,
            "explanation": "데이터를 청크로 나누면 여러 프로세스가 병렬로 처리하여 전체 성능이 향상됩니다."
        },
        {
            "id": 13,
            "type": "multiple_choice",
            "difficulty": "intermediate",
            "question": "ParallelProcessingFramework에서 futures를 사용하는 이유는?",
            "options": [
                "메모리 효율성",
                "비동기 작업 관리 및 결과 수집",
                "오류 방지",
                "코드 가독성"
            ],
            "correct": 1,
            "explanation": "futures는 비동기로 실행되는 작업을 관리하고 나중에 결과를 수집할 수 있게 해줍니다."
        },
        {
            "id": 14,
            "type": "multiple_choice",
            "difficulty": "advanced",
            "question": "분산 작업 큐에서 작업 재시도 로직이 중요한 이유는?",
            "options": [
                "성능 최적화",
                "일시적 장애에 대한 복원력 제공",
                "메모리 사용량 최적화",
                "코드 단순화"
            ],
            "correct": 1,
            "explanation": "분산 환경에서는 네트워크 장애, 노드 장애 등 일시적 문제가 빈번하므로 재시도 로직이 시스템 복원력을 제공합니다."
        },
        {
            "id": 15,
            "type": "multiple_choice",
            "difficulty": "advanced",
            "question": "TaskHandler 패턴의 주요 이점은?",
            "options": [
                "메모리 사용량 감소",
                "작업 타입별 처리 로직 분리 및 확장성",
                "처리 속도 향상",
                "오류 감소"
            ],
            "correct": 1,
            "explanation": "TaskHandler 패턴은 각 작업 타입별로 처리 로직을 분리하여 코드의 확장성과 유지보수성을 향상시킵니다."
        },
        {
            "id": 16,
            "type": "multiple_choice",
            "difficulty": "advanced",
            "question": "분산 워커 시스템에서 워커 상태 관리가 중요한 이유는?",
            "options": [
                "메모리 절약",
                "워커 장애 감지 및 작업 재할당",
                "처리 속도 향상",
                "코드 복잡도 감소"
            ],
            "correct": 1,
            "explanation": "워커 상태를 관리해야 장애가 발생한 워커를 감지하고 해당 워커의 작업을 다른 워커에게 재할당할 수 있습니다."
        },
        {
            "id": 17,
            "type": "multiple_choice",
            "difficulty": "advanced",
            "question": "ConcurrencyProfiler에서 CPU 시간과 벽시계 시간의 차이가 나는 이유는?",
            "options": [
                "측정 오류",
                "I/O 대기 시간과 멀티스레딩 오버헤드",
                "메모리 부족",
                "컴파일러 최적화"
            ],
            "correct": 1,
            "explanation": "CPU 시간은 실제 CPU가 작업한 시간이고, 벽시계 시간은 I/O 대기, 스레드 스위칭 등을 포함한 전체 경과 시간입니다."
        },
        {
            "id": 18,
            "type": "multiple_choice",
            "difficulty": "advanced",
            "question": "메모리 프로파일링에서 peak memory와 current memory의 차이점은?",
            "options": [
                "측정 시점의 차이",
                "peak는 최대 사용량, current는 현재 사용량",
                "측정 단위의 차이",
                "측정 방법의 차이"
            ],
            "correct": 1,
            "explanation": "peak memory는 프로그램 실행 중 최대로 사용된 메모리양이고, current memory는 현재 시점의 메모리 사용량입니다."
        },
        {
            "id": 19,
            "type": "code_analysis",
            "difficulty": "advanced",
            "question": "다음 코드에서 잠재적인 데드락 상황을 설명하고 해결 방법을 제시하세요:\n\n```python\nlock1 = threading.Lock()\nlock2 = threading.Lock()\n\ndef thread1():\n    with lock1:\n        time.sleep(0.1)\n        with lock2:\n            print(\"Thread 1\")\n\ndef thread2():\n    with lock2:\n        time.sleep(0.1)\n        with lock1:\n            print(\"Thread 2\")\n```",
            "options": [
                "데드락 없음, 정상 동작",
                "lock1, lock2 순서로 획득하면 데드락 없음",
                "두 스레드가 서로 다른 순서로 락을 획득하여 데드락 발생 가능, 락 순서 통일 필요",
                "타임아웃 설정으로 해결 가능"
            ],
            "correct": 2,
            "explanation": "thread1은 lock1→lock2 순서로, thread2는 lock2→lock1 순서로 락을 획득하려 하므로 순환 대기 상태로 데드락이 발생할 수 있습니다. 모든 스레드에서 동일한 순서로 락을 획득하도록 수정해야 합니다."
        },
        {
            "id": 20,
            "type": "code_analysis",
            "difficulty": "expert",
            "question": "비동기 서킷 브레이커에서 HALF_OPEN 상태의 의미와 중요성을 설명하세요.",
            "options": [
                "완전히 닫힌 상태로 모든 요청 허용",
                "완전히 열린 상태로 모든 요청 차단",
                "제한적 복구 시도 상태로 일부 요청만 허용하여 서비스 복구 여부 확인",
                "오류 로깅 전용 상태"
            ],
            "correct": 2,
            "explanation": "HALF_OPEN 상태는 서비스가 복구되었는지 확인하기 위해 제한적으로 요청을 허용하는 상태입니다. 성공하면 CLOSED로, 실패하면 다시 OPEN으로 전환됩니다."
        },
        {
            "id": 21,
            "type": "design_question",
            "difficulty": "expert",
            "question": "고가용성 분산 작업 처리 시스템을 설계할 때 고려해야 할 핵심 요소들을 설명하세요.",
            "options": [
                "단순한 로드 밸런싱만 고려",
                "장애 감지, 자동 복구, 데이터 일관성, 확장성, 모니터링",
                "성능 최적화만 고려",
                "비용 절감만 고려"
            ],
            "correct": 1,
            "explanation": "고가용성 시스템에서는 장애 감지 및 자동 복구, 데이터 일관성 보장, 수평적 확장성, 실시간 모니터링이 핵심 요소입니다."
        },
        {
            "id": 22,
            "type": "performance_analysis",
            "difficulty": "expert",
            "question": "CPU 집약적 작업과 I/O 집약적 작업에 대한 최적의 동시성 전략을 비교 설명하세요.",
            "options": [
                "모든 경우에 멀티스레딩 사용",
                "CPU 집약적: 멀티프로세싱, I/O 집약적: 비동기/멀티스레딩",
                "모든 경우에 비동기 사용",
                "모든 경우에 멀티프로세싱 사용"
            ],
            "correct": 1,
            "explanation": "CPU 집약적 작업은 GIL로 인해 멀티프로세싱이 유리하고, I/O 집약적 작업은 비동기나 멀티스레딩이 효율적입니다."
        },
        {
            "id": 23,
            "type": "optimization",
            "difficulty": "expert",
            "question": "메모리 사용량을 최적화하면서 동시성 성능을 유지하는 전략은?",
            "options": [
                "무제한 스레드 생성",
                "스레드/프로세스 풀 사용, 객체 재사용, 지연 로딩",
                "단일 스레드만 사용",
                "메모리 무시하고 성능만 고려"
            ],
            "correct": 1,
            "explanation": "풀 패턴으로 리소스 재사용, 객체 재사용으로 가비지 컬렉션 부담 감소, 지연 로딩으로 필요시에만 메모리 사용이 효과적입니다."
        },
        {
            "id": 24,
            "type": "troubleshooting",
            "difficulty": "expert",
            "question": "분산 시스템에서 부분 실패(partial failure) 상황을 처리하는 방법은?",
            "options": [
                "전체 시스템 재시작",
                "무시하고 계속 진행",
                "타임아웃, 재시도, 서킷 브레이커, 우아한 성능 저하",
                "로그만 남기고 방치"
            ],
            "correct": 2,
            "explanation": "부분 실패는 타임아웃 설정, 지능적 재시도, 서킷 브레이커 패턴, 우아한 성능 저하(graceful degradation)로 처리해야 합니다."
        },
        {
            "id": 25,
            "type": "architecture",
            "difficulty": "expert",
            "question": "마이크로서비스 환경에서 동시성과 확장성을 고려한 설계 원칙은?",
            "options": [
                "단일 거대한 서비스로 통합",
                "상태 비저장, 비동기 통신, 이벤트 기반 아키텍처, 자동 확장",
                "동기적 통신만 사용",
                "모든 서비스 간 강한 결합"
            ],
            "correct": 1,
            "explanation": "마이크로서비스는 상태 비저장(stateless), 비동기 메시징, 이벤트 기반 아키텍처, 자동 확장(auto-scaling)을 통해 동시성과 확장성을 확보합니다."
        }
    ]
}