# Chapter 2: íŒŒì¼ ì²˜ë¦¬ì™€ ë°ì´í„° í˜•ì‹ (File Processing and Data Formats)

## í•™ìŠµ ëª©í‘œ
ì´ ì±•í„°ë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- JSON ë°ì´í„°ë¥¼ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜í•˜ê³  ì²˜ë¦¬í•˜ê¸°
- CSV íŒŒì¼ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì½ê³  ì“°ë©° ë¶„ì„í•˜ê¸°
- XML ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ê³  ì¡°ì‘í•˜ê¸°
- ë°”ì´ë„ˆë¦¬ íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸°
- ì••ì¶• íŒŒì¼(ZIP, TAR)ì„ ìƒì„±í•˜ê³  í•´ì œí•˜ê¸°
- ì„¤ì • íŒŒì¼ì„ ê´€ë¦¬í•˜ê³  í™œìš©í•˜ê¸°
- íŒŒì¼ ì‹œìŠ¤í…œì„ íƒìƒ‰í•˜ê³  ê´€ë¦¬í•˜ê¸°
- ë°ì´í„° ì§ë ¬í™”/ì—­ì§ë ¬í™” ê°œë… ì´í•´í•˜ê¸°

## 1. JSON íŒŒì¼ ì²˜ë¦¬

### 1.1 JSON ê¸°ë³¸ ê°œë…ê³¼ ì²˜ë¦¬

```python
import json
import datetime
from decimal import Decimal

print("=== JSON ê¸°ë³¸ ì²˜ë¦¬ ===")

# íŒŒì´ì¬ ê°ì²´ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
data = {
    "name": "ê¹€ì² ìˆ˜",
    "age": 30,
    "city": "ì„œìš¸",
    "hobbies": ["ë…ì„œ", "ì˜í™”ê°ìƒ", "í”„ë¡œê·¸ë˜ë°"],
    "is_student": False,
    "grades": {
        "math": 85,
        "english": 92,
        "science": 78
    }
}

# JSON ë¬¸ìì—´ë¡œ ë³€í™˜
json_string = json.dumps(data, ensure_ascii=False, indent=2)
print("JSON ë¬¸ìì—´:")
print(json_string)

# JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜
parsed_data = json.loads(json_string)
print(f"\níŒŒì‹±ëœ ë°ì´í„°: {parsed_data}")
print(f"ì´ë¦„: {parsed_data['name']}")
print(f"ì·¨ë¯¸ë“¤: {', '.join(parsed_data['hobbies'])}")

# JSON íŒŒì¼ ì“°ê¸°
with open('student_data.json', 'w', encoding='utf-8') as file:
    json.dump(data, file, ensure_ascii=False, indent=2)
    
print("\nJSON íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: student_data.json")

# JSON íŒŒì¼ ì½ê¸°
with open('student_data.json', 'r', encoding='utf-8') as file:
    loaded_data = json.load(file)
    
print(f"íŒŒì¼ì—ì„œ ì½ì€ ë°ì´í„°: {loaded_data}")
```

### 1.2 ë³µí•© JSON ë°ì´í„° ì²˜ë¦¬

```python
# ë³µì¡í•œ JSON ë°ì´í„° ì˜ˆì œ
complex_data = {
    "metadata": {
        "version": "1.0",
        "created_at": "2024-01-01T10:00:00Z",
        "author": "Python Tutorial"
    },
    "students": [
        {
            "id": 1,
            "name": "ê¹€ì² ìˆ˜",
            "courses": [
                {"name": "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°", "grade": 'A', "credits": 3},
                {"name": "ë°ì´í„° êµ¬ì¡°", "grade": 'B+', "credits": 3}
            ],
            "contact": {
                "email": "kim@email.com",
                "phone": "010-1234-5678"
            }
        },
        {
            "id": 2,
            "name": "ì´ì˜í¬",
            "courses": [
                {"name": "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°", "grade": 'A+', "credits": 3},
                {"name": "ì•Œê³ ë¦¬ì¦˜", "grade": 'A', "credits": 4}
            ],
            "contact": {
                "email": "lee@email.com",
                "phone": "010-9876-5432"
            }
        }
    ]
}

print("\n=== ë³µí•© JSON ë°ì´í„° ì²˜ë¦¬ ===")

# JSON íŒŒì¼ë¡œ ì €ì¥
with open('school_data.json', 'w', encoding='utf-8') as file:
    json.dump(complex_data, file, ensure_ascii=False, indent=2)

# ë°ì´í„° ë¶„ì„ í•¨ìˆ˜ë“¤
def analyze_student_data(data):
    """í•™ìƒ ë°ì´í„° ë¶„ì„"""
    students = data['students']
    
    print(f"ì´ í•™ìƒ ìˆ˜: {len(students)}")
    
    # ê° í•™ìƒì˜ ì´ í•™ì  ê³„ì‚°
    for student in students:
        total_credits = sum(course['credits'] for course in student['courses'])
        print(f"{student['name']}: {total_credits}í•™ì ")
    
    # ê³¼ëª©ë³„ ìˆ˜ê°• í•™ìƒ ìˆ˜
    course_count = {}
    for student in students:
        for course in student['courses']:
            course_name = course['name']
            course_count[course_name] = course_count.get(course_name, 0) + 1
    
    print("\nê³¼ëª©ë³„ ìˆ˜ê°• í•™ìƒ ìˆ˜:")
    for course, count in course_count.items():
        print(f"  {course}: {count}ëª…")

def find_student_by_id(data, student_id):
    """IDë¡œ í•™ìƒ ì°¾ê¸°"""
    for student in data['students']:
        if student['id'] == student_id:
            return student
    return None

# ë°ì´í„° ë¶„ì„ ì‹¤í–‰
analyze_student_data(complex_data)

# íŠ¹ì • í•™ìƒ ì°¾ê¸°
student = find_student_by_id(complex_data, 1)
if student:
    print(f"\ní•™ìƒ ì •ë³´: {student['name']}")
    print(f"ì´ë©”ì¼: {student['contact']['email']}")
```

### 1.3 JSON ì§ë ¬í™” ê³ ê¸‰ ê¸°ë²•

```python
import json
from datetime import datetime, date
from decimal import Decimal

class DateTimeEncoder(json.JSONEncoder):
    """ë‚ ì§œ/ì‹œê°„ ê°ì²´ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ëŠ” ì»¤ìŠ¤í…€ ì¸ì½”ë”"""
    def default(self, obj):
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)

class Person:
    """ì‚¬ìš©ì ì •ì˜ í´ë˜ìŠ¤"""
    def __init__(self, name, birth_date, salary):
        self.name = name
        self.birth_date = birth_date
        self.salary = salary
    
    def to_dict(self):
        """ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'name': self.name,
            'birth_date': self.birth_date,
            'salary': self.salary
        }
    
    @classmethod
    def from_dict(cls, data):
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°ì²´ ìƒì„±"""
        return cls(
            data['name'],
            datetime.fromisoformat(data['birth_date']).date(),
            Decimal(str(data['salary']))
        )

print("\n=== JSON ì§ë ¬í™” ê³ ê¸‰ ê¸°ë²• ===")

# ë³µì¡í•œ ë°ì´í„° íƒ€ì…ì„ í¬í•¨í•œ ê°ì²´
person = Person(
    "ê¹€ì² ìˆ˜",
    date(1990, 5, 15),
    Decimal('3500000.50')
)

# ì»¤ìŠ¤í…€ ì¸ì½”ë” ì‚¬ìš©
person_dict = person.to_dict()
json_data = json.dumps(person_dict, cls=DateTimeEncoder, ensure_ascii=False, indent=2)
print("ì§ë ¬í™”ëœ ë°ì´í„°:")
print(json_data)

# ì—­ì§ë ¬í™”
loaded_dict = json.loads(json_data)
restored_person = Person.from_dict(loaded_dict)

print(f"\në³µì›ëœ ê°ì²´:")
print(f"ì´ë¦„: {restored_person.name}")
print(f"ìƒë…„ì›”ì¼: {restored_person.birth_date}")
print(f"ê¸‰ì—¬: {restored_person.salary}")

# JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦ í•¨ìˆ˜
def validate_json_structure(data, schema):
    """ê°„ë‹¨í•œ JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
    def check_type(value, expected_type):
        if expected_type == 'string':
            return isinstance(value, str)
        elif expected_type == 'number':
            return isinstance(value, (int, float))
        elif expected_type == 'boolean':
            return isinstance(value, bool)
        elif expected_type == 'array':
            return isinstance(value, list)
        elif expected_type == 'object':
            return isinstance(value, dict)
        return False
    
    for key, expected_type in schema.items():
        if key not in data:
            return False, f"í•„ìˆ˜ í•„ë“œ '{key}'ê°€ ì—†ìŠµë‹ˆë‹¤"
        
        if not check_type(data[key], expected_type):
            return False, f"í•„ë“œ '{key}'ì˜ íƒ€ì…ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆìƒ: {expected_type}"
    
    return True, "ìœ íš¨í•œ êµ¬ì¡°ì…ë‹ˆë‹¤"

# ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì˜ˆì œ
user_schema = {
    'name': 'string',
    'age': 'number',
    'email': 'string',
    'is_active': 'boolean'
}

valid_user = {
    'name': 'ê¹€ì² ìˆ˜',
    'age': 30,
    'email': 'kim@email.com',
    'is_active': True
}

invalid_user = {
    'name': 'ì´ì˜í¬',
    'age': '25',  # ë¬¸ìì—´ì´ì§€ë§Œ ìˆ«ìì—¬ì•¼ í•¨
    'email': 'lee@email.com'
    # is_active í•„ë“œ ëˆ„ë½
}

print(f"\n=== JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦ ===")
is_valid, message = validate_json_structure(valid_user, user_schema)
print(f"ìœ íš¨í•œ ì‚¬ìš©ì: {is_valid} - {message}")

is_valid, message = validate_json_structure(invalid_user, user_schema)
print(f"ë¬´íš¨í•œ ì‚¬ìš©ì: {is_valid} - {message}")
```

## 2. CSV íŒŒì¼ ì²˜ë¦¬

### 2.1 CSV ê¸°ë³¸ ì²˜ë¦¬

```python
import csv
from io import StringIO

print("\n=== CSV ê¸°ë³¸ ì²˜ë¦¬ ===")

# CSV ë°ì´í„° ìƒì„±
students_data = [
    ['ì´ë¦„', 'ë‚˜ì´', 'ë„ì‹œ', 'ì„±ì '],
    ['ê¹€ì² ìˆ˜', 25, 'ì„œìš¸', 85],
    ['ì´ì˜í¬', 23, 'ë¶€ì‚°', 92],
    ['ë°•ë¯¼ìˆ˜', 24, 'ëŒ€êµ¬', 78],
    ['ìµœì§€ì›', 22, 'ì¸ì²œ', 95]
]

# CSV íŒŒì¼ ì“°ê¸°
with open('students.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerows(students_data)

print("CSV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: students.csv")

# CSV íŒŒì¼ ì½ê¸°
with open('students.csv', 'r', encoding='utf-8') as csvfile:
    reader = csv.reader(csvfile)
    
    print("\nCSV íŒŒì¼ ë‚´ìš©:")
    for row_num, row in enumerate(reader):
        if row_num == 0:
            print(f"í—¤ë”: {row}")
        else:
            print(f"í•™ìƒ {row_num}: {row}")

# DictReaderì™€ DictWriter ì‚¬ìš©
print("\n=== DictReaderì™€ DictWriter ===")

# DictWriterë¡œ ì“°ê¸°
fieldnames = ['name', 'age', 'city', 'grade']
students_dict = [
    {'name': 'ê¹€ì² ìˆ˜', 'age': 25, 'city': 'ì„œìš¸', 'grade': 85},
    {'name': 'ì´ì˜í¬', 'age': 23, 'city': 'ë¶€ì‚°', 'grade': 92},
    {'name': 'ë°•ë¯¼ìˆ˜', 'age': 24, 'city': 'ëŒ€êµ¬', 'grade': 78},
    {'name': 'ìµœì§€ì›', 'age': 22, 'city': 'ì¸ì²œ', 'grade': 95}
]

with open('students_dict.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(students_dict)

# DictReaderë¡œ ì½ê¸°
with open('students_dict.csv', 'r', encoding='utf-8') as csvfile:
    reader = csv.DictReader(csvfile)
    
    print("DictReaderë¡œ ì½ì€ ë°ì´í„°:")
    for row in reader:
        print(f"{row['name']}: {row['age']}ì„¸, {row['city']}, ì„±ì  {row['grade']}")
```

### 2.2 CSV ë°ì´í„° ë¶„ì„ ë° ì²˜ë¦¬

```python
import csv
import statistics
from collections import defaultdict, Counter

def create_sample_sales_data():
    """ìƒ˜í”Œ íŒë§¤ ë°ì´í„° ìƒì„±"""
    sales_data = [
        ['date', 'product', 'category', 'quantity', 'price', 'salesperson'],
        ['2024-01-01', 'ë…¸íŠ¸ë¶', 'ì „ìì œí’ˆ', 2, 1200000, 'ê¹€ì² ìˆ˜'],
        ['2024-01-02', 'ë§ˆìš°ìŠ¤', 'ì „ìì œí’ˆ', 5, 25000, 'ì´ì˜í¬'],
        ['2024-01-03', 'í‚¤ë³´ë“œ', 'ì „ìì œí’ˆ', 3, 80000, 'ê¹€ì² ìˆ˜'],
        ['2024-01-04', 'ëª¨ë‹ˆí„°', 'ì „ìì œí’ˆ', 1, 300000, 'ë°•ë¯¼ìˆ˜'],
        ['2024-01-05', 'í—¤ë“œí°', 'ì „ìì œí’ˆ', 4, 150000, 'ì´ì˜í¬'],
        ['2024-01-06', 'ìŠ¤í”¼ì»¤', 'ì „ìì œí’ˆ', 2, 200000, 'ê¹€ì² ìˆ˜'],
        ['2024-01-07', 'ì›¹ìº ', 'ì „ìì œí’ˆ', 6, 100000, 'ë°•ë¯¼ìˆ˜'],
        ['2024-01-08', 'íƒœë¸”ë¦¿', 'ì „ìì œí’ˆ', 1, 800000, 'ì´ì˜í¬'],
    ]
    
    with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerows(sales_data)

def analyze_sales_data():
    """íŒë§¤ ë°ì´í„° ë¶„ì„"""
    print("\n=== CSV ë°ì´í„° ë¶„ì„ ===")
    
    # ë°ì´í„° ì½ê¸° ë° ë³€í™˜
    sales_records = []
    with open('sales_data.csv', 'r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            # ë°ì´í„° íƒ€ì… ë³€í™˜
            record = {
                'date': row['date'],
                'product': row['product'],
                'category': row['category'],
                'quantity': int(row['quantity']),
                'price': int(row['price']),
                'salesperson': row['salesperson']
            }
            record['total_sales'] = record['quantity'] * record['price']
            sales_records.append(record)
    
    # ì´ ë§¤ì¶œ ê³„ì‚°
    total_revenue = sum(record['total_sales'] for record in sales_records)
    print(f"ì´ ë§¤ì¶œ: {total_revenue:,}ì›")
    
    # íŒë§¤ì›ë³„ ë§¤ì¶œ
    salesperson_sales = defaultdict(int)
    for record in sales_records:
        salesperson_sales[record['salesperson']] += record['total_sales']
    
    print("\níŒë§¤ì›ë³„ ë§¤ì¶œ:")
    for person, sales in sorted(salesperson_sales.items(), key=lambda x: x[1], reverse=True):
        print(f"  {person}: {sales:,}ì›")
    
    # ì œí’ˆë³„ íŒë§¤ ìˆ˜ëŸ‰
    product_quantity = defaultdict(int)
    for record in sales_records:
        product_quantity[record['product']] += record['quantity']
    
    print("\nì œí’ˆë³„ íŒë§¤ ìˆ˜ëŸ‰:")
    for product, quantity in sorted(product_quantity.items(), key=lambda x: x[1], reverse=True):
        print(f"  {product}: {quantity}ê°œ")
    
    # í‰ê·  ë‹¨ê°€ ê³„ì‚°
    prices = [record['price'] for record in sales_records]
    avg_price = statistics.mean(prices)
    median_price = statistics.median(prices)
    
    print(f"\nê°€ê²© í†µê³„:")
    print(f"  í‰ê·  ë‹¨ê°€: {avg_price:,.0f}ì›")
    print(f"  ì¤‘ê°„ ë‹¨ê°€: {median_price:,}ì›")
    print(f"  ìµœê³  ë‹¨ê°€: {max(prices):,}ì›")
    print(f"  ìµœì € ë‹¨ê°€: {min(prices):,}ì›")

def export_analysis_results():
    """ë¶„ì„ ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    # íŒë§¤ì›ë³„ ìš”ì•½ ë°ì´í„° ìƒì„±
    with open('sales_data.csv', 'r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        
        salesperson_stats = defaultdict(lambda: {
            'total_sales': 0,
            'total_quantity': 0,
            'products_sold': set()
        })
        
        for row in reader:
            person = row['salesperson']
            quantity = int(row['quantity'])
            price = int(row['price'])
            
            salesperson_stats[person]['total_sales'] += quantity * price
            salesperson_stats[person]['total_quantity'] += quantity
            salesperson_stats[person]['products_sold'].add(row['product'])
    
    # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
    summary_data = []
    for person, stats in salesperson_stats.items():
        summary_data.append({
            'salesperson': person,
            'total_sales': stats['total_sales'],
            'total_quantity': stats['total_quantity'],
            'unique_products': len(stats['products_sold']),
            'avg_sale_amount': stats['total_sales'] // stats['total_quantity']
        })
    
    # CSV íŒŒì¼ë¡œ ì €ì¥
    with open('sales_summary.csv', 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = ['salesperson', 'total_sales', 'total_quantity', 'unique_products', 'avg_sale_amount']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(summary_data)
    
    print("\níŒë§¤ì› ìš”ì•½ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: sales_summary.csv")

# ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë° ë¶„ì„ ì‹¤í–‰
create_sample_sales_data()
analyze_sales_data()
export_analysis_results()
```

### 2.3 CSV íŒŒì¼ ê³ ê¸‰ ì²˜ë¦¬ ê¸°ë²•

```python
import csv
from datetime import datetime
import re

class CSVProcessor:
    """CSV íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self, filename, delimiter=',', quotechar='"'):
        self.filename = filename
        self.delimiter = delimiter
        self.quotechar = quotechar
        self.data = []
        self.headers = []
    
    def load_data(self):
        """CSV íŒŒì¼ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.filename, 'r', encoding='utf-8') as csvfile:
                # êµ¬ë¶„ì ìë™ ê°ì§€
                sample = csvfile.read(1024)
                csvfile.seek(0)
                
                sniffer = csv.Sniffer()
                dialect = sniffer.sniff(sample)
                
                reader = csv.DictReader(csvfile, dialect=dialect)
                self.headers = reader.fieldnames
                self.data = list(reader)
                
            print(f"âœ“ {len(self.data)}ê°œì˜ ë ˆì½”ë“œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return True
            
        except FileNotFoundError:
            print(f"âœ— íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.filename}")
            return False
        except Exception as e:
            print(f"âœ— íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def validate_data(self, validation_rules):
        """ë°ì´í„° ê²€ì¦"""
        errors = []
        
        for row_num, row in enumerate(self.data, 1):
            for field, rule in validation_rules.items():
                if field not in row:
                    continue
                
                value = row[field].strip()
                
                # í•„ìˆ˜ í•„ë“œ ì²´í¬
                if rule.get('required', False) and not value:
                    errors.append(f"í–‰ {row_num}: '{field}' í•„ë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    continue
                
                # ë°ì´í„° íƒ€ì… ì²´í¬
                if value and 'type' in rule:
                    if rule['type'] == 'int':
                        try:
                            int(value)
                        except ValueError:
                            errors.append(f"í–‰ {row_num}: '{field}'ëŠ” ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {value})")
                    
                    elif rule['type'] == 'float':
                        try:
                            float(value)
                        except ValueError:
                            errors.append(f"í–‰ {row_num}: '{field}'ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {value})")
                    
                    elif rule['type'] == 'email':
                        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
                        if not re.match(email_pattern, value):
                            errors.append(f"í–‰ {row_num}: '{field}'ëŠ” ìœ íš¨í•œ ì´ë©”ì¼ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {value})")
                
                # ë²”ìœ„ ì²´í¬
                if value and 'range' in rule:
                    try:
                        num_value = float(value)
                        min_val, max_val = rule['range']
                        if not (min_val <= num_value <= max_val):
                            errors.append(f"í–‰ {row_num}: '{field}'ëŠ” {min_val}~{max_val} ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {value})")
                    except ValueError:
                        pass  # íƒ€ì… ì²´í¬ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
        
        return errors
    
    def filter_data(self, conditions):
        """ì¡°ê±´ì— ë”°ë¥¸ ë°ì´í„° í•„í„°ë§"""
        filtered_data = []
        
        for row in self.data:
            match = True
            
            for field, condition in conditions.items():
                if field not in row:
                    match = False
                    break
                
                value = row[field].strip()
                operator = condition.get('operator', '==')
                target = condition.get('value')
                
                try:
                    # ìˆ«ì ë¹„êµ
                    if isinstance(target, (int, float)):
                        value = float(value)
                        if operator == '==' and value != target:
                            match = False
                        elif operator == '>' and value <= target:
                            match = False
                        elif operator == '<' and value >= target:
                            match = False
                        elif operator == '>=' and value < target:
                            match = False
                        elif operator == '<=' and value > target:
                            match = False
                    
                    # ë¬¸ìì—´ ë¹„êµ
                    else:
                        if operator == '==' and value != target:
                            match = False
                        elif operator == 'contains' and target not in value:
                            match = False
                        elif operator == 'startswith' and not value.startswith(target):
                            match = False
                
                except ValueError:
                    match = False
                    
                if not match:
                    break
            
            if match:
                filtered_data.append(row)
        
        return filtered_data
    
    def save_data(self, data, output_filename):
        """ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        if not data:
            print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            with open(output_filename, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=self.headers)
                writer.writeheader()
                writer.writerows(data)
            
            print(f"âœ“ {len(data)}ê°œì˜ ë ˆì½”ë“œê°€ {output_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âœ— íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

# CSV í”„ë¡œì„¸ì„œ ì‚¬ìš© ì˜ˆì œ
print("\n=== CSV ê³ ê¸‰ ì²˜ë¦¬ ì˜ˆì œ ===")

# ìƒ˜í”Œ ì§ì› ë°ì´í„° ìƒì„±
employee_data = [
    ['name', 'age', 'department', 'salary', 'email'],
    ['ê¹€ì² ìˆ˜', '28', 'IT', '3500000', 'kim@company.com'],
    ['ì´ì˜í¬', '32', 'HR', '4000000', 'lee@company.com'],
    ['ë°•ë¯¼ìˆ˜', '', 'IT', '3200000', 'park@company.com'],  # ë‚˜ì´ ëˆ„ë½
    ['ìµœì§€ì›', '29', 'Sales', '3800000', 'choi-invalid-email'],  # ì˜ëª»ëœ ì´ë©”ì¼
    ['ì •í˜„ìš°', '35', 'IT', 'invalid', 'jung@company.com'],  # ì˜ëª»ëœ ê¸‰ì—¬
    ['í•œë¯¸ì˜', '27', 'Marketing', '3600000', 'han@company.com']
]

with open('employees.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerows(employee_data)

# CSV í”„ë¡œì„¸ì„œ ì‚¬ìš©
processor = CSVProcessor('employees.csv')

if processor.load_data():
    # ë°ì´í„° ê²€ì¦ ê·œì¹™ ì •ì˜
    validation_rules = {
        'name': {'required': True},
        'age': {'required': True, 'type': 'int', 'range': (18, 65)},
        'salary': {'required': True, 'type': 'int', 'range': (2000000, 10000000)},
        'email': {'required': True, 'type': 'email'}
    }
    
    # ë°ì´í„° ê²€ì¦
    errors = processor.validate_data(validation_rules)
    if errors:
        print("\në°ì´í„° ê²€ì¦ ì˜¤ë¥˜:")
        for error in errors:
            print(f"  â€¢ {error}")
    else:
        print("\nâœ“ ëª¨ë“  ë°ì´í„°ê°€ ìœ íš¨í•©ë‹ˆë‹¤.")
    
    # ë°ì´í„° í•„í„°ë§ (IT ë¶€ì„œ, ê¸‰ì—¬ 3500000 ì´ìƒ)
    filtered_data = processor.filter_data({
        'department': {'operator': '==', 'value': 'IT'},
        'salary': {'operator': '>=', 'value': 3500000}
    })
    
    print(f"\ní•„í„°ë§ ê²°ê³¼: {len(filtered_data)}ê°œì˜ ë ˆì½”ë“œ")
    for record in filtered_data:
        print(f"  {record['name']}: {record['department']}, {record['salary']}ì›")
    
    # í•„í„°ë§ëœ ë°ì´í„° ì €ì¥
    if filtered_data:
        processor.save_data(filtered_data, 'it_high_salary.csv')
```

## 3. XML íŒŒì¼ ì²˜ë¦¬

### 3.1 XML ê¸°ë³¸ íŒŒì‹±

```python
import xml.etree.ElementTree as ET
from xml.dom import minidom

print("\n=== XML ê¸°ë³¸ ì²˜ë¦¬ ===")

# XML ë¬¸ì„œ ìƒì„±
def create_sample_xml():
    """ìƒ˜í”Œ XML ë°ì´í„° ìƒì„±"""
    root = ET.Element("library")
    
    # ì±… 1
    book1 = ET.SubElement(root, "book", id="1")
    ET.SubElement(book1, "title").text = "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°"
    ET.SubElement(book1, "author").text = "ê¹€ì² ìˆ˜"
    ET.SubElement(book1, "year").text = "2023"
    ET.SubElement(book1, "price").text = "25000"
    ET.SubElement(book1, "category").text = "programming"
    
    # ì±… 2
    book2 = ET.SubElement(root, "book", id="2")
    ET.SubElement(book2, "title").text = "ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤"
    ET.SubElement(book2, "author").text = "ì´ì˜í¬"
    ET.SubElement(book2, "year").text = "2024"
    ET.SubElement(book2, "price").text = "30000"
    ET.SubElement(book2, "category").text = "data-science"
    
    # ì±… 3
    book3 = ET.SubElement(root, "book", id="3")
    ET.SubElement(book3, "title").text = "ì›¹ ê°œë°œ"
    ET.SubElement(book3, "author").text = "ë°•ë¯¼ìˆ˜"
    ET.SubElement(book3, "year").text = "2023"
    ET.SubElement(book3, "price").text = "28000"
    ET.SubElement(book3, "category").text = "web-development"
    
    return root

# XML íŒŒì¼ ìƒì„± ë° ì €ì¥
xml_root = create_sample_xml()

# ì˜ˆì˜ê²Œ í¬ë§·íŒ…í•˜ì—¬ ì €ì¥
def prettify_xml(element):
    """XMLì„ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…"""
    rough_string = ET.tostring(element, encoding='unicode')
    reparsed = minidom.parseString(rough_string)
    return reparsed.toprettyxml(indent="  ")

with open('library.xml', 'w', encoding='utf-8') as f:
    f.write(prettify_xml(xml_root))

print("XML íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: library.xml")

# XML íŒŒì¼ ì½ê¸° ë° íŒŒì‹±
tree = ET.parse('library.xml')
root = tree.getroot()

print(f"\në£¨íŠ¸ ì—˜ë¦¬ë¨¼íŠ¸: {root.tag}")

# ëª¨ë“  ì±… ì •ë³´ ì¶œë ¥
print("\nëª¨ë“  ì±… ì •ë³´:")
for book in root.findall('book'):
    book_id = book.get('id')
    title = book.find('title').text
    author = book.find('author').text
    year = book.find('year').text
    price = book.find('price').text
    category = book.find('category').text
    
    print(f"  ì±… ID {book_id}: {title}")
    print(f"    ì €ì: {author}")
    print(f"    ì¶œíŒì—°ë„: {year}")
    print(f"    ê°€ê²©: {price}ì›")
    print(f"    ì¹´í…Œê³ ë¦¬: {category}")
    print()
```

### 3.2 XML ê³ ê¸‰ ì¡°ì‘

```python
import xml.etree.ElementTree as ET
from datetime import datetime

class XMLLibraryManager:
    """XML ë„ì„œê´€ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, xml_file):
        self.xml_file = xml_file
        try:
            self.tree = ET.parse(xml_file)
            self.root = self.tree.getroot()
        except FileNotFoundError:
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            self.root = ET.Element("library")
            self.tree = ET.ElementTree(self.root)
            self.save()
    
    def add_book(self, title, author, year, price, category):
        """ìƒˆ ì±… ì¶”ê°€"""
        # ìƒˆë¡œìš´ ID ìƒì„±
        existing_ids = [int(book.get('id', 0)) for book in self.root.findall('book')]
        new_id = max(existing_ids, default=0) + 1
        
        # ìƒˆ ì±… ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
        book = ET.SubElement(self.root, "book", id=str(new_id))
        ET.SubElement(book, "title").text = title
        ET.SubElement(book, "author").text = author
        ET.SubElement(book, "year").text = str(year)
        ET.SubElement(book, "price").text = str(price)
        ET.SubElement(book, "category").text = category
        ET.SubElement(book, "added_date").text = datetime.now().isoformat()
        
        self.save()
        print(f"âœ“ ì±…ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤: {title} (ID: {new_id})")
        return new_id
    
    def find_books_by_author(self, author):
        """ì €ìë³„ ì±… ê²€ìƒ‰"""
        books = []
        for book in self.root.findall('book'):
            if book.find('author').text == author:
                books.append(self._book_to_dict(book))
        return books
    
    def find_books_by_category(self, category):
        """ì¹´í…Œê³ ë¦¬ë³„ ì±… ê²€ìƒ‰"""
        books = []
        for book in self.root.findall('book'):
            if book.find('category').text == category:
                books.append(self._book_to_dict(book))
        return books
    
    def find_books_by_price_range(self, min_price, max_price):
        """ê°€ê²© ë²”ìœ„ë¡œ ì±… ê²€ìƒ‰"""
        books = []
        for book in self.root.findall('book'):
            price = int(book.find('price').text)
            if min_price <= price <= max_price:
                books.append(self._book_to_dict(book))
        return books
    
    def update_book_price(self, book_id, new_price):
        """ì±… ê°€ê²© ì—…ë°ì´íŠ¸"""
        book = self.root.find(f".//book[@id='{book_id}']")
        if book is not None:
            book.find('price').text = str(new_price)
            # ìˆ˜ì •ì¼ ì¶”ê°€
            updated_date = book.find('updated_date')
            if updated_date is None:
                updated_date = ET.SubElement(book, 'updated_date')
            updated_date.text = datetime.now().isoformat()
            
            self.save()
            print(f"âœ“ ì±… ID {book_id}ì˜ ê°€ê²©ì´ {new_price}ì›ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        else:
            print(f"âœ— ì±… ID {book_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
    
    def delete_book(self, book_id):
        """ì±… ì‚­ì œ"""
        book = self.root.find(f".//book[@id='{book_id}']")
        if book is not None:
            title = book.find('title').text
            self.root.remove(book)
            self.save()
            print(f"âœ“ ì±…ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤: {title} (ID: {book_id})")
            return True
        else:
            print(f"âœ— ì±… ID {book_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
    
    def get_statistics(self):
        """ë„ì„œê´€ í†µê³„"""
        books = self.root.findall('book')
        total_books = len(books)
        
        if total_books == 0:
            return {"total_books": 0}
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì±… ìˆ˜
        categories = {}
        total_value = 0
        years = []
        
        for book in books:
            category = book.find('category').text
            categories[category] = categories.get(category, 0) + 1
            
            price = int(book.find('price').text)
            total_value += price
            
            year = int(book.find('year').text)
            years.append(year)
        
        return {
            "total_books": total_books,
            "categories": categories,
            "total_value": total_value,
            "average_price": total_value // total_books,
            "newest_year": max(years),
            "oldest_year": min(years)
        }
    
    def _book_to_dict(self, book_element):
        """XML ì—˜ë¦¬ë¨¼íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'id': book_element.get('id'),
            'title': book_element.find('title').text,
            'author': book_element.find('author').text,
            'year': int(book_element.find('year').text),
            'price': int(book_element.find('price').text),
            'category': book_element.find('category').text
        }
    
    def save(self):
        """XML íŒŒì¼ ì €ì¥"""
        # ì˜ˆì˜ê²Œ í¬ë§·íŒ…í•˜ì—¬ ì €ì¥
        with open(self.xml_file, 'w', encoding='utf-8') as f:
            f.write(prettify_xml(self.root))

# XML ë„ì„œê´€ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš© ì˜ˆì œ
print("\n=== XML ë„ì„œê´€ ê´€ë¦¬ ì‹œìŠ¤í…œ ===")

# ë„ì„œê´€ ë§¤ë‹ˆì € ìƒì„±
library = XMLLibraryManager('library.xml')

# ìƒˆ ì±… ì¶”ê°€
library.add_book("ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ", "ì •í˜„ìš°", 2024, 35000, "machine-learning")
library.add_book("ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„", "í•œë¯¸ì˜", 2023, 32000, "programming")

# ì €ìë³„ ê²€ìƒ‰
print("\nê¹€ì² ìˆ˜ê°€ ì“´ ì±…:")
kim_books = library.find_books_by_author("ê¹€ì² ìˆ˜")
for book in kim_books:
    print(f"  {book['title']} ({book['year']}) - {book['price']:,}ì›")

# ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
print("\ní”„ë¡œê·¸ë˜ë° ê´€ë ¨ ì±…:")
programming_books = library.find_books_by_category("programming")
for book in programming_books:
    print(f"  {book['title']} by {book['author']} - {book['price']:,}ì›")

# ê°€ê²© ë²”ìœ„ ê²€ìƒ‰
print("\n25,000ì› ~ 30,000ì› ì±…:")
mid_price_books = library.find_books_by_price_range(25000, 30000)
for book in mid_price_books:
    print(f"  {book['title']} - {book['price']:,}ì›")

# ê°€ê²© ì—…ë°ì´íŠ¸
library.update_book_price("1", 27000)

# í†µê³„ ì¶œë ¥
stats = library.get_statistics()
print(f"\n=== ë„ì„œê´€ í†µê³„ ===")
print(f"ì´ ì±… ìˆ˜: {stats['total_books']}ê¶Œ")
print(f"ì´ ê°€ì¹˜: {stats['total_value']:,}ì›")
print(f"í‰ê·  ê°€ê²©: {stats['average_price']:,}ì›")
print(f"ì¶œíŒ ì—°ë„: {stats['oldest_year']} ~ {stats['newest_year']}")
print("ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
for category, count in stats['categories'].items():
    print(f"  {category}: {count}ê¶Œ")
```

### 3.3 XML ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì²˜ë¦¬

```python
import xml.etree.ElementTree as ET

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ìˆëŠ” XML ë¬¸ì„œ ìƒì„±
def create_namespaced_xml():
    """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ìˆëŠ” XML ë¬¸ì„œ ìƒì„±"""
    namespaces = {
        '': 'http://example.com/library',
        'meta': 'http://example.com/metadata',
        'auth': 'http://example.com/author'
    }
    
    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë“±ë¡
    for prefix, uri in namespaces.items():
        ET.register_namespace(prefix, uri)
    
    root = ET.Element("{http://example.com/library}library")
    root.set("{http://www.w3.org/2001/XMLSchema-instance}schemaLocation", 
             "http://example.com/library library.xsd")
    
    # ë©”íƒ€ë°ì´í„°
    metadata = ET.SubElement(root, "{http://example.com/metadata}metadata")
    ET.SubElement(metadata, "{http://example.com/metadata}version").text = "1.0"
    ET.SubElement(metadata, "{http://example.com/metadata}created").text = "2024-01-01"
    
    # ì±… ì •ë³´
    book = ET.SubElement(root, "{http://example.com/library}book")
    book.set("id", "1")
    
    ET.SubElement(book, "{http://example.com/library}title").text = "Python Programming"
    
    # ì €ì ì •ë³´ (ë‹¤ë¥¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤)
    author = ET.SubElement(book, "{http://example.com/author}author")
    ET.SubElement(author, "{http://example.com/author}name").text = "ê¹€ì² ìˆ˜"
    ET.SubElement(author, "{http://example.com/author}email").text = "kim@email.com"
    
    return root

print("\n=== XML ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì²˜ë¦¬ ===")

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ XML ìƒì„±
ns_root = create_namespaced_xml()

# íŒŒì¼ë¡œ ì €ì¥
with open('library_ns.xml', 'wb') as f:
    ET.ElementTree(ns_root).write(f, encoding='utf-8', xml_declaration=True)

print("ë„¤ì„ìŠ¤í˜ì´ìŠ¤ XML íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: library_ns.xml")

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ XML ì½ê¸°
tree = ET.parse('library_ns.xml')
root = tree.getroot()

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
namespaces = {
    'lib': 'http://example.com/library',
    'meta': 'http://example.com/metadata',
    'auth': 'http://example.com/author'
}

print("\në„¤ì„ìŠ¤í˜ì´ìŠ¤ XML íŒŒì‹±:")

# ë©”íƒ€ë°ì´í„° ì½ê¸°
metadata = root.find('meta:metadata', namespaces)
if metadata is not None:
    version = metadata.find('meta:version', namespaces).text
    created = metadata.find('meta:created', namespaces).text
    print(f"ë²„ì „: {version}, ìƒì„±ì¼: {created}")

# ì±… ì •ë³´ ì½ê¸°
book = root.find('lib:book', namespaces)
if book is not None:
    title = book.find('lib:title', namespaces).text
    print(f"ì±… ì œëª©: {title}")
    
    # ì €ì ì •ë³´ ì½ê¸°
    author = book.find('auth:author', namespaces)
    if author is not None:
        name = author.find('auth:name', namespaces).text
        email = author.find('auth:email', namespaces).text
        print(f"ì €ì: {name} ({email})")
```

## 4. ë°”ì´ë„ˆë¦¬ íŒŒì¼ ì²˜ë¦¬

### 4.1 ë°”ì´ë„ˆë¦¬ íŒŒì¼ ê¸°ë³¸ ì²˜ë¦¬

```python
import struct
import os
from datetime import datetime

print("\n=== ë°”ì´ë„ˆë¦¬ íŒŒì¼ ì²˜ë¦¬ ===")

# ë°”ì´ë„ˆë¦¬ ë°ì´í„° ìƒì„± ë° ì €ì¥
def create_binary_data():
    """ë°”ì´ë„ˆë¦¬ ë°ì´í„° íŒŒì¼ ìƒì„±"""
    # í•™ìƒ ë ˆì½”ë“œ êµ¬ì¡°: ID(4ë°”ì´íŠ¸), ì´ë¦„(20ë°”ì´íŠ¸), ë‚˜ì´(1ë°”ì´íŠ¸), ì„±ì (4ë°”ì´íŠ¸ float)
    students = [
        (1, "ê¹€ì² ìˆ˜", 25, 85.5),
        (2, "ì´ì˜í¬", 23, 92.0),
        (3, "ë°•ë¯¼ìˆ˜", 24, 78.5),
        (4, "ìµœì§€ì›", 22, 95.0)
    ]
    
    with open('students.bin', 'wb') as f:
        for student_id, name, age, grade in students:
            # ë°ì´í„° íŒ¨í‚¹: I=unsigned int, 20s=20ë°”ì´íŠ¸ ë¬¸ìì—´, B=unsigned char, f=float
            name_bytes = name.encode('utf-8')[:20].ljust(20, b'\x00')
            packed_data = struct.pack('I20sBf', student_id, name_bytes, age, grade)
            f.write(packed_data)
    
    print("ë°”ì´ë„ˆë¦¬ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: students.bin")
    return len(students)

def read_binary_data():
    """ë°”ì´ë„ˆë¦¬ ë°ì´í„° íŒŒì¼ ì½ê¸°"""
    print("\në°”ì´ë„ˆë¦¬ íŒŒì¼ ì½ê¸°:")
    
    record_size = struct.calcsize('I20sBf')  # ë ˆì½”ë“œ í¬ê¸° ê³„ì‚°
    
    with open('students.bin', 'rb') as f:
        record_num = 1
        while True:
            data = f.read(record_size)
            if not data:
                break
            
            # ë°ì´í„° ì–¸íŒ¨í‚¹
            student_id, name_bytes, age, grade = struct.unpack('I20sBf', data)
            name = name_bytes.rstrip(b'\x00').decode('utf-8')
            
            print(f"í•™ìƒ {record_num}: ID={student_id}, ì´ë¦„={name}, ë‚˜ì´={age}, ì„±ì ={grade:.1f}")
            record_num += 1

def update_binary_record(record_index, new_grade):
    """íŠ¹ì • ë ˆì½”ë“œì˜ ì„±ì  ì—…ë°ì´íŠ¸"""
    record_size = struct.calcsize('I20sBf')
    
    # íŒŒì¼ì„ ì½ê¸°/ì“°ê¸° ëª¨ë“œë¡œ ì—´ê¸°
    with open('students.bin', 'r+b') as f:
        # í•´ë‹¹ ë ˆì½”ë“œ ìœ„ì¹˜ë¡œ ì´ë™
        f.seek(record_index * record_size)
        
        # ê¸°ì¡´ ë°ì´í„° ì½ê¸°
        data = f.read(record_size)
        if data:
            student_id, name_bytes, age, old_grade = struct.unpack('I20sBf', data)
            
            # ì„±ì ë§Œ ë³€ê²½í•˜ì—¬ ë‹¤ì‹œ íŒ¨í‚¹
            new_data = struct.pack('I20sBf', student_id, name_bytes, age, new_grade)
            
            # íŒŒì¼ í¬ì¸í„°ë¥¼ ë‹¤ì‹œ í•´ë‹¹ ìœ„ì¹˜ë¡œ ì´ë™
            f.seek(record_index * record_size)
            f.write(new_data)
            
            name = name_bytes.rstrip(b'\x00').decode('utf-8')
            print(f"âœ“ {name}ì˜ ì„±ì ì´ {old_grade:.1f}ì—ì„œ {new_grade:.1f}ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âœ— í•´ë‹¹ ë ˆì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ë°”ì´ë„ˆë¦¬ íŒŒì¼ ì²˜ë¦¬ ì‹¤í–‰
student_count = create_binary_data()
read_binary_data()

# ë‘ ë²ˆì§¸ í•™ìƒ(ì¸ë±ìŠ¤ 1)ì˜ ì„±ì  ì—…ë°ì´íŠ¸
update_binary_record(1, 95.5)

print("\nì—…ë°ì´íŠ¸ í›„ ë°ì´í„°:")
read_binary_data()
```

### 4.2 ì´ë¯¸ì§€ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì²˜ë¦¬

```python
import struct
import os

def read_bmp_header(filename):
    """BMP íŒŒì¼ í—¤ë” ì½ê¸°"""
    try:
        with open(filename, 'rb') as f:
            # BMP íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ í™•ì¸
            signature = f.read(2)
            if signature != b'BM':
                print("âœ— BMP íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
                return None
            
            # íŒŒì¼ í¬ê¸°
            file_size = struct.unpack('<I', f.read(4))[0]
            
            # ì˜ˆì•½ í•„ë“œ ê±´ë„ˆë›°ê¸°
            f.read(4)
            
            # ì´ë¯¸ì§€ ë°ì´í„° ì˜¤í”„ì…‹
            data_offset = struct.unpack('<I', f.read(4))[0]
            
            # DIB í—¤ë” í¬ê¸°
            dib_header_size = struct.unpack('<I', f.read(4))[0]
            
            # ì´ë¯¸ì§€ í¬ê¸°
            width = struct.unpack('<I', f.read(4))[0]
            height = struct.unpack('<I', f.read(4))[0]
            
            # ìƒ‰ìƒ í‰ë©´ ìˆ˜
            color_planes = struct.unpack('<H', f.read(2))[0]
            
            # ë¹„íŠ¸ per í”½ì…€
            bits_per_pixel = struct.unpack('<H', f.read(2))[0]
            
            return {
                'file_size': file_size,
                'width': width,
                'height': height,
                'bits_per_pixel': bits_per_pixel,
                'data_offset': data_offset
            }
            
    except FileNotFoundError:
        print(f"âœ— íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
        return None
    except Exception as e:
        print(f"âœ— íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def create_simple_bmp():
    """ê°„ë‹¨í•œ BMP íŒŒì¼ ìƒì„± (2x2 í”½ì…€, ë¹¨ê°„ìƒ‰)"""
    # BMP í—¤ë” ìƒì„±
    width, height = 2, 2
    bits_per_pixel = 24
    
    # í•œ í–‰ì˜ ë°”ì´íŠ¸ ìˆ˜ (4ë°”ì´íŠ¸ ê²½ê³„ë¡œ ì •ë ¬)
    row_size = ((width * bits_per_pixel + 31) // 32) * 4
    pixel_data_size = row_size * height
    file_size = 54 + pixel_data_size  # 54ëŠ” í—¤ë” í¬ê¸°
    
    with open('simple.bmp', 'wb') as f:
        # BMP íŒŒì¼ í—¤ë” (14ë°”ì´íŠ¸)
        f.write(b'BM')  # ì‹œê·¸ë‹ˆì²˜
        f.write(struct.pack('<I', file_size))  # íŒŒì¼ í¬ê¸°
        f.write(struct.pack('<I', 0))  # ì˜ˆì•½ í•„ë“œ
        f.write(struct.pack('<I', 54))  # ë°ì´í„° ì˜¤í”„ì…‹
        
        # DIB í—¤ë” (40ë°”ì´íŠ¸)
        f.write(struct.pack('<I', 40))  # DIB í—¤ë” í¬ê¸°
        f.write(struct.pack('<I', width))  # ë„ˆë¹„
        f.write(struct.pack('<I', height))  # ë†’ì´
        f.write(struct.pack('<H', 1))  # ìƒ‰ìƒ í‰ë©´
        f.write(struct.pack('<H', bits_per_pixel))  # ë¹„íŠ¸/í”½ì…€
        f.write(struct.pack('<I', 0))  # ì••ì¶• ë°©ì‹
        f.write(struct.pack('<I', pixel_data_size))  # ì´ë¯¸ì§€ í¬ê¸°
        f.write(struct.pack('<I', 2835))  # X í•´ìƒë„
        f.write(struct.pack('<I', 2835))  # Y í•´ìƒë„
        f.write(struct.pack('<I', 0))  # ìƒ‰ìƒ ìˆ˜
        f.write(struct.pack('<I', 0))  # ì¤‘ìš”í•œ ìƒ‰ìƒ ìˆ˜
        
        # í”½ì…€ ë°ì´í„° (BGR ìˆœì„œ, ì•„ë˜ìª½ë¶€í„°)
        for y in range(height):
            for x in range(width):
                # ë¹¨ê°„ìƒ‰ í”½ì…€ (BGR: 0, 0, 255)
                f.write(struct.pack('BBB', 0, 0, 255))
            
            # í–‰ íŒ¨ë”©
            padding = row_size - (width * 3)
            f.write(b'\x00' * padding)
    
    print("ê°„ë‹¨í•œ BMP íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: simple.bmp")

print("\n=== ì´ë¯¸ì§€ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì²˜ë¦¬ ===")

# ê°„ë‹¨í•œ BMP íŒŒì¼ ìƒì„±
create_simple_bmp()

# BMP íŒŒì¼ í—¤ë” ì½ê¸°
bmp_info = read_bmp_header('simple.bmp')
if bmp_info:
    print("\nBMP íŒŒì¼ ì •ë³´:")
    print(f"  íŒŒì¼ í¬ê¸°: {bmp_info['file_size']:,} ë°”ì´íŠ¸")
    print(f"  ì´ë¯¸ì§€ í¬ê¸°: {bmp_info['width']} x {bmp_info['height']} í”½ì…€")
    print(f"  ìƒ‰ìƒ ê¹Šì´: {bmp_info['bits_per_pixel']} ë¹„íŠ¸/í”½ì…€")
    print(f"  ë°ì´í„° ì˜¤í”„ì…‹: {bmp_info['data_offset']} ë°”ì´íŠ¸")
```

## 5. ì••ì¶• íŒŒì¼ ì²˜ë¦¬

### 5.1 ZIP íŒŒì¼ ì²˜ë¦¬

```python
import zipfile
import os
from datetime import datetime

print("\n=== ZIP íŒŒì¼ ì²˜ë¦¬ ===")

def create_sample_files():
    """ì••ì¶•í•  ìƒ˜í”Œ íŒŒì¼ë“¤ ìƒì„±"""
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('sample_project', exist_ok=True)
    os.makedirs('sample_project/src', exist_ok=True)
    os.makedirs('sample_project/docs', exist_ok=True)
    
    # Python ì†ŒìŠ¤ íŒŒì¼
    with open('sample_project/src/main.py', 'w', encoding='utf-8') as f:
        f.write('''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë“ˆ
"""

def main():
    print("Hello, World!")
    return 0

if __name__ == "__main__":
    main()
''')
    
    # ì„¤ì • íŒŒì¼
    with open('sample_project/config.json', 'w', encoding='utf-8') as f:
        f.write('''{
  "app_name": "Sample App",
  "version": "1.0.0",
  "debug": true,
  "database": {
    "host": "localhost",
    "port": 5432
  }
}''')
    
    # README íŒŒì¼
    with open('sample_project/README.md', 'w', encoding='utf-8') as f:
        f.write('''# Sample Project

ì´ê²ƒì€ ìƒ˜í”Œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ì„¤ì¹˜ ë°©ë²•

1. Python 3.8 ì´ìƒ ì„¤ì¹˜
2. ì˜ì¡´ì„± ì„¤ì¹˜: `pip install -r requirements.txt`
3. ì‹¤í–‰: `python src/main.py`

## ë¼ì´ì„ ìŠ¤

MIT License
''')
    
    # ë¬¸ì„œ íŒŒì¼
    with open('sample_project/docs/api.md', 'w', encoding='utf-8') as f:
        f.write('''# API ë¬¸ì„œ

## í•¨ìˆ˜ ëª©ë¡

### main()
- ì„¤ëª…: ë©”ì¸ í•¨ìˆ˜
- ë°˜í™˜ê°’: int (0: ì„±ê³µ, 1: ì‹¤íŒ¨)
''')
    
    print("ìƒ˜í”Œ íŒŒì¼ë“¤ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def create_zip_archive():
    """ZIP ì••ì¶• íŒŒì¼ ìƒì„±"""
    with zipfile.ZipFile('sample_project.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:
        # ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì••ì¶•
        for root, dirs, files in os.walk('sample_project'):
            for file in files:
                file_path = os.path.join(root, file)
                archive_path = os.path.relpath(file_path, '.')
                zipf.write(file_path, archive_path)
                print(f"ì••ì¶•ë¨: {archive_path}")
    
    print("\nâœ“ ZIP íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: sample_project.zip")

def analyze_zip_archive(zip_filename):
    """ZIP íŒŒì¼ ë¶„ì„"""
    print(f"\n=== {zip_filename} ë¶„ì„ ===")
    
    with zipfile.ZipFile(zip_filename, 'r') as zipf:
        file_list = zipf.filelist
        
        print(f"ì´ íŒŒì¼ ìˆ˜: {len(file_list)}")
        
        total_compressed = 0
        total_uncompressed = 0
        
        print("\níŒŒì¼ ëª©ë¡:")
        for file_info in file_list:
            total_compressed += file_info.compress_size
            total_uncompressed += file_info.file_size
            
            # ì••ì¶•ë¥  ê³„ì‚°
            if file_info.file_size > 0:
                compression_ratio = (1 - file_info.compress_size / file_info.file_size) * 100
            else:
                compression_ratio = 0
            
            # ìˆ˜ì • ì‹œê°„
            date_time = datetime(*file_info.date_time)
            
            print(f"  {file_info.filename}")
            print(f"    í¬ê¸°: {file_info.file_size:,} â†’ {file_info.compress_size:,} ë°”ì´íŠ¸ ({compression_ratio:.1f}% ì••ì¶•)")
            print(f"    ìˆ˜ì •ì¼: {date_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        overall_compression = (1 - total_compressed / total_uncompressed) * 100 if total_uncompressed > 0 else 0
        print(f"\nì „ì²´ ì••ì¶•ë¥ : {overall_compression:.1f}%")
        print(f"ì••ì¶• ì „ í¬ê¸°: {total_uncompressed:,} ë°”ì´íŠ¸")
        print(f"ì••ì¶• í›„ í¬ê¸°: {total_compressed:,} ë°”ì´íŠ¸")

def extract_zip_archive(zip_filename, extract_path='extracted'):
    """ZIP íŒŒì¼ ì••ì¶• í•´ì œ"""
    os.makedirs(extract_path, exist_ok=True)
    
    with zipfile.ZipFile(zip_filename, 'r') as zipf:
        print(f"\n{zip_filename}ì„ {extract_path}ì— ì••ì¶• í•´ì œ ì¤‘...")
        
        for file_info in zipf.filelist:
            zipf.extract(file_info, extract_path)
            print(f"  ì¶”ì¶œë¨: {file_info.filename}")
        
        print("âœ“ ì••ì¶• í•´ì œ ì™„ë£Œ")

def create_selective_zip():
    """ì¡°ê±´ë¶€ íŒŒì¼ ì••ì¶•"""
    with zipfile.ZipFile('python_files.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk('sample_project'):
            for file in files:
                # Python íŒŒì¼ê³¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë§Œ ì••ì¶•
                if file.endswith(('.py', '.md')):
                    file_path = os.path.join(root, file)
                    archive_path = os.path.relpath(file_path, '.')
                    zipf.write(file_path, archive_path)
                    print(f"ì„ íƒì  ì••ì¶•: {archive_path}")
    
    print("\nâœ“ Python ë° Markdown íŒŒì¼ë§Œ ì••ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤: python_files.zip")

# ZIP íŒŒì¼ ì²˜ë¦¬ ì‹¤í–‰
create_sample_files()
create_zip_archive()
analyze_zip_archive('sample_project.zip')
extract_zip_archive('sample_project.zip')
create_selective_zip()
```

### 5.2 TAR íŒŒì¼ ì²˜ë¦¬

```python
import tarfile
import os
import gzip
import time

print("\n=== TAR íŒŒì¼ ì²˜ë¦¬ ===")

def create_tar_archive():
    """TAR ì••ì¶• íŒŒì¼ ìƒì„± (ë‹¤ì–‘í•œ ì••ì¶• ë°©ì‹)"""
    
    # ì¼ë°˜ TAR íŒŒì¼
    with tarfile.open('sample_project.tar', 'w') as tar:
        tar.add('sample_project', arcname='sample_project')
    print("âœ“ TAR íŒŒì¼ ìƒì„±: sample_project.tar")
    
    # GZIP ì••ì¶• TAR íŒŒì¼
    with tarfile.open('sample_project.tar.gz', 'w:gz') as tar:
        tar.add('sample_project', arcname='sample_project')
    print("âœ“ TAR.GZ íŒŒì¼ ìƒì„±: sample_project.tar.gz")
    
    # BZIP2 ì••ì¶• TAR íŒŒì¼
    with tarfile.open('sample_project.tar.bz2', 'w:bz2') as tar:
        tar.add('sample_project', arcname='sample_project')
    print("âœ“ TAR.BZ2 íŒŒì¼ ìƒì„±: sample_project.tar.bz2")

def analyze_tar_archive(tar_filename):
    """TAR íŒŒì¼ ë¶„ì„"""
    print(f"\n=== {tar_filename} ë¶„ì„ ===")
    
    with tarfile.open(tar_filename, 'r') as tar:
        members = tar.getmembers()
        
        print(f"ì´ í•­ëª© ìˆ˜: {len(members)}")
        
        file_count = 0
        dir_count = 0
        total_size = 0
        
        print("\në‚´ìš© ëª©ë¡:")
        for member in members:
            if member.isfile():
                file_count += 1
                total_size += member.size
                print(f"  ğŸ“„ {member.name} ({member.size:,} ë°”ì´íŠ¸)")
            elif member.isdir():
                dir_count += 1
                print(f"  ğŸ“ {member.name}/")
            
            # ê¶Œí•œ ì •ë³´
            mode = oct(member.mode)[-3:]
            mtime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(member.mtime))
            print(f"      ê¶Œí•œ: {mode}, ìˆ˜ì •ì¼: {mtime}")
        
        print(f"\nìš”ì•½:")
        print(f"  íŒŒì¼: {file_count}ê°œ")
        print(f"  ë””ë ‰í† ë¦¬: {dir_count}ê°œ")
        print(f"  ì´ í¬ê¸°: {total_size:,} ë°”ì´íŠ¸")

def extract_specific_files(tar_filename, pattern='*.py'):
    """íŠ¹ì • íŒ¨í„´ì˜ íŒŒì¼ë§Œ ì¶”ì¶œ"""
    import fnmatch
    
    extract_path = 'tar_extracted'
    os.makedirs(extract_path, exist_ok=True)
    
    with tarfile.open(tar_filename, 'r') as tar:
        members = tar.getmembers()
        
        extracted_files = []
        for member in members:
            if member.isfile() and fnmatch.fnmatch(member.name, pattern):
                tar.extract(member, extract_path)
                extracted_files.append(member.name)
        
        print(f"\n'{pattern}' íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ë“¤ì´ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤:")
        for filename in extracted_files:
            print(f"  {filename}")

def create_incremental_backup():
    """ì¦ë¶„ ë°±ì—… ì‹œë®¬ë ˆì´ì…˜"""
    # ì²« ë²ˆì§¸ ë°±ì—… (ì „ì²´)
    backup_name = f"backup_full_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tar.gz"
    with tarfile.open(backup_name, 'w:gz') as tar:
        tar.add('sample_project', arcname='sample_project')
    print(f"âœ“ ì „ì²´ ë°±ì—… ìƒì„±: {backup_name}")
    
    # íŒŒì¼ ìˆ˜ì • ì‹œë®¬ë ˆì´ì…˜
    with open('sample_project/src/main.py', 'a', encoding='utf-8') as f:
        f.write('\n# ìˆ˜ì •ëœ ë‚´ìš©\nprint("Updated!")\n')
    
    # ìƒˆ íŒŒì¼ ì¶”ê°€
    with open('sample_project/new_file.txt', 'w', encoding='utf-8') as f:
        f.write('ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ì…ë‹ˆë‹¤.')
    
    # ìˆ˜ì •ëœ íŒŒì¼ë“¤ë§Œ ë°±ì—… (ê°„ë‹¨í•œ ì¦ë¶„ ë°±ì—…)
    incremental_name = f"backup_incremental_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tar.gz"
    
    with tarfile.open(incremental_name, 'w:gz') as tar:
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ì´ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”
        for root, dirs, files in os.walk('sample_project'):
            for file in files:
                file_path = os.path.join(root, file)
                # ìµœê·¼ ìˆ˜ì •ëœ íŒŒì¼ë“¤ë§Œ í¬í•¨ (ì˜ˆ: ìµœê·¼ 1ì‹œê°„ ì´ë‚´)
                stat = os.stat(file_path)
                if time.time() - stat.st_mtime < 3600:  # 1ì‹œê°„ = 3600ì´ˆ
                    archive_path = os.path.relpath(file_path, '.')
                    tar.add(file_path, arcname=archive_path)
    
    print(f"âœ“ ì¦ë¶„ ë°±ì—… ìƒì„±: {incremental_name}")

# TAR íŒŒì¼ ì²˜ë¦¬ ì‹¤í–‰
create_tar_archive()

# íŒŒì¼ í¬ê¸° ë¹„êµ
archives = ['sample_project.tar', 'sample_project.tar.gz', 'sample_project.tar.bz2']
print("\nì••ì¶• ë°©ì‹ë³„ íŒŒì¼ í¬ê¸° ë¹„êµ:")
for archive in archives:
    if os.path.exists(archive):
        size = os.path.getsize(archive)
        print(f"  {archive}: {size:,} ë°”ì´íŠ¸")

analyze_tar_archive('sample_project.tar.gz')
extract_specific_files('sample_project.tar.gz', '*.py')
create_incremental_backup()
```

## 6. ì„¤ì • íŒŒì¼ ê´€ë¦¬

### 6.1 ConfigParser ì‚¬ìš©

```python
import configparser
import os
from datetime import datetime

print("\n=== ì„¤ì • íŒŒì¼ ê´€ë¦¬ ===")

def create_sample_config():
    """ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±"""
    config = configparser.ConfigParser()
    
    # ê¸°ë³¸ ì„¹ì…˜ ì„¤ì •
    config['DEFAULT'] = {
        'debug': 'False',
        'log_level': 'INFO',
        'max_connections': '100'
    }
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    config['database'] = {
        'host': 'localhost',
        'port': '5432',
        'username': 'admin',
        'password': 'secret123',
        'database_name': 'myapp'
    }
    
    # ì›¹ ì„œë²„ ì„¤ì •
    config['webserver'] = {
        'host': '0.0.0.0',
        'port': '8080',
        'workers': '4',
        'timeout': '30'
    }
    
    # ë¡œê¹… ì„¤ì •
    config['logging'] = {
        'log_file': '/var/log/myapp.log',
        'max_size': '10MB',
        'backup_count': '5',
        'log_level': 'DEBUG'  # DEFAULTì˜ log_levelì„ ì˜¤ë²„ë¼ì´ë“œ
    }
    
    # íŒŒì¼ë¡œ ì €ì¥
    with open('app_config.ini', 'w') as configfile:
        config.write(configfile)
    
    print("âœ“ ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: app_config.ini")

def read_config():
    """ì„¤ì • íŒŒì¼ ì½ê¸°"""
    config = configparser.ConfigParser()
    config.read('app_config.ini')
    
    print("\nì„¤ì • íŒŒì¼ ë‚´ìš©:")
    
    # ëª¨ë“  ì„¹ì…˜ ì¶œë ¥
    for section_name in config.sections():
        print(f"\n[{section_name}]")
        for key, value in config[section_name].items():
            print(f"  {key} = {value}")
    
    # íŠ¹ì • ê°’ ì ‘ê·¼
    print(f"\níŠ¹ì • ì„¤ì • ê°’ ì ‘ê·¼:")
    print(f"  ë°ì´í„°ë² ì´ìŠ¤ í˜¸ìŠ¤íŠ¸: {config['database']['host']}")
    print(f"  ì›¹ ì„œë²„ í¬íŠ¸: {config.getint('webserver', 'port')}")
    print(f"  ë””ë²„ê·¸ ëª¨ë“œ: {config.getboolean('database', 'debug')}")  # DEFAULTì—ì„œ ìƒì†
    print(f"  ë¡œê·¸ ë ˆë²¨: {config['logging']['log_level']}")  # ì˜¤ë²„ë¼ì´ë“œëœ ê°’

class AppConfig:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_file='app_config.ini'):
        self.config_file = config_file
        self.config = configparser.ConfigParser()
        self.load_config()
    
    def load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if os.path.exists(self.config_file):
            self.config.read(self.config_file)
            print(f"âœ“ ì„¤ì • íŒŒì¼ ë¡œë“œë¨: {self.config_file}")
        else:
            print(f"âš  ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.config_file}")
            self.create_default_config()
    
    def create_default_config(self):
        """ê¸°ë³¸ ì„¤ì • ìƒì„±"""
        self.config['DEFAULT'] = {
            "created_at": datetime.now().isoformat(),
            "version": "1.0.0"
        }
        
        self.config['app'] = {
            'name': 'MyApplication',
            'debug': 'False'
        }
        
        self.save_config()
        print("âœ“ ê¸°ë³¸ ì„¤ì • íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def get(self, section, key, fallback=None):
        """ì„¤ì • ê°’ ê°€ì ¸ì˜¤ê¸°"""
        try:
            return self.config.get(section, key, fallback=fallback)
        except (configparser.NoSectionError, configparser.NoOptionError):
            return fallback
    
    def getint(self, section, key, fallback=0):
        """ì •ìˆ˜ ì„¤ì • ê°’ ê°€ì ¸ì˜¤ê¸°"""
        try:
            return self.config.getint(section, key, fallback=fallback)
        except (configparser.NoSectionError, configparser.NoOptionError, ValueError):
            return fallback
    
    def getboolean(self, section, key, fallback=False):
        """ë¶ˆë¦° ì„¤ì • ê°’ ê°€ì ¸ì˜¤ê¸°"""
        try:
            return self.config.getboolean(section, key, fallback=fallback)
        except (configparser.NoSectionError, configparser.NoOptionError, ValueError):
            return fallback
    
    def set(self, section, key, value):
        """ì„¤ì • ê°’ ë³€ê²½"""
        if not self.config.has_section(section):
            self.config.add_section(section)
        
        self.config.set(section, key, str(value))
        print(f"ì„¤ì • ë³€ê²½: [{section}] {key} = {value}")
    
    def save_config(self):
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        with open(self.config_file, 'w') as configfile:
            self.config.write(configfile)
        print(f"âœ“ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {self.config_file}")
    
    def list_all_settings(self):
        """ëª¨ë“  ì„¤ì • ë‚˜ì—´"""
        print("\ní˜„ì¬ ì„¤ì •:")
        for section_name in self.config.sections():
            print(f"\n[{section_name}]")
            for key in self.config[section_name]:
                value = self.config[section_name][key]
                print(f"  {key} = {value}")

# ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤ ì‚¬ìš© ì˜ˆì œ
print("\n=== ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤ ì‚¬ìš© ===")

create_sample_config()
read_config()

# ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤ ì‚¬ìš©
app_config = AppConfig('my_app.ini')

# ì„¤ì • ê°’ ì½ê¸°
app_name = app_config.get('app', 'name', 'Unknown App')
debug_mode = app_config.getboolean('app', 'debug', False)

print(f"\nì• í”Œë¦¬ì¼€ì´ì…˜: {app_name}")
print(f"ë””ë²„ê·¸ ëª¨ë“œ: {debug_mode}")

# ì„¤ì • ê°’ ë³€ê²½
app_config.set('app', 'debug', True)
app_config.set('app', 'last_updated', datetime.now().isoformat())
app_config.set('performance', 'cache_enabled', True)

# ì„¤ì • ì €ì¥
app_config.save_config()

# ëª¨ë“  ì„¤ì • ì¶œë ¥
app_config.list_all_settings()
```

### 6.2 JSONê³¼ YAML ì„¤ì • íŒŒì¼

```python
import json
import os
from datetime import datetime

# YAMLì€ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë¯€ë¡œ try-exceptë¡œ ì²˜ë¦¬
try:
    import yaml
    YAML_AVAILABLE = True
except ImportError:
    YAML_AVAILABLE = False
    print("âš  PyYAMLì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. YAML ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install PyYAML'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

class ConfigManager:
    """ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì„¤ì • íŒŒì¼ ê´€ë¦¬"""
    
    def __init__(self, config_file):
        self.config_file = config_file
        self.config_data = {}
        self.file_format = self._detect_format()
        self.load()
    
    def _detect_format(self):
        """íŒŒì¼ í™•ì¥ìë¡œ í˜•ì‹ ê°ì§€"""
        _, ext = os.path.splitext(self.config_file)
        ext = ext.lower()
        
        if ext == '.json':
            return 'json'
        elif ext in ['.yml', '.yaml'] and YAML_AVAILABLE:
            return 'yaml'
        elif ext == '.ini':
            return 'ini'
        else:
            return 'json'  # ê¸°ë³¸ê°’
    
    def load(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if not os.path.exists(self.config_file):
            self.create_default_config()
            return
        
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                if self.file_format == 'json':
                    self.config_data = json.load(f)
                elif self.file_format == 'yaml':
                    self.config_data = yaml.safe_load(f)
                
            print(f"âœ“ ì„¤ì • íŒŒì¼ ë¡œë“œë¨: {self.config_file} ({self.file_format.upper()})")
        
        except Exception as e:
            print(f"âœ— ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.create_default_config()
    
    def create_default_config(self):
        """ê¸°ë³¸ ì„¤ì • ìƒì„±"""
        self.config_data = {
            "application": {
                "name": "MyApp",
                "version": "1.0.0",
                "debug": False,
                "created_at": datetime.now().isoformat()
            },
            "database": {
                "type": "postgresql",
                "host": "localhost",
                "port": 5432,
                "name": "myapp_db",
                "connection_pool": {
                    "min_connections": 1,
                    "max_connections": 20
                }
            },
            "logging": {
                "level": "INFO",
                "handlers": [
                    {
                        "type": "file",
                        "filename": "app.log",
                        "max_size": "10MB",
                        "backup_count": 5
                    },
                    {
                        "type": "console",
                        "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
                    }
                ]
            },
            "features": {
                "email_notifications": True,
                "api_rate_limit": 1000,
                "allowed_file_types": ["jpg", "png", "pdf", "txt"],
                "maintenance_mode": False
            }
        }
        self.save()
        print(f"âœ“ ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±ë¨: {self.config_file}")
    
    def get(self, path, default=None):
        """ì  í‘œê¸°ë²•ìœ¼ë¡œ ì„¤ì • ê°’ ê°€ì ¸ì˜¤ê¸° (ì˜ˆ: 'database.host')"""
        keys = path.split('.')
        current = self.config_data
        
        try:
            for key in keys:
                current = current[key]
            return current
        except (KeyError, TypeError):
            return default
    
    def set(self, path, value):
        """ì  í‘œê¸°ë²•ìœ¼ë¡œ ì„¤ì • ê°’ ë³€ê²½"""
        keys = path.split('.')
        current = self.config_data
        
        # ì¤‘ê°„ ë”•ì…”ë„ˆë¦¬ë“¤ì„ ìƒì„±
        for key in keys[:-1]:
            if key not in current or not isinstance(current[key], dict):
                current[key] = {}
            current = current[key]
        
        # ë§ˆì§€ë§‰ í‚¤ì— ê°’ ì„¤ì •
        current[keys[-1]] = value
        print(f"ì„¤ì • ë³€ê²½: {path} = {value}")
    
    def delete(self, path):
        """ì„¤ì • ì‚­ì œ"""
        keys = path.split('.')
        current = self.config_data
        
        try:
            for key in keys[:-1]:
                current = current[key]
            
            if keys[-1] in current:
                del current[keys[-1]]
                print(f"ì„¤ì • ì‚­ì œ: {path}")
                return True
            else:
                print(f"ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
                return False
        except (KeyError, TypeError):
            print(f"ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
            return False
    
    def save(self):
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                if self.file_format == 'json':
                    json.dump(self.config_data, f, ensure_ascii=False, indent=2)
                elif self.file_format == 'yaml':
                    yaml.dump(self.config_data, f, default_flow_style=False, allow_unicode=True)
            
            print(f"âœ“ ì„¤ì • ì €ì¥ë¨: {self.config_file}")
        
        except Exception as e:
            print(f"âœ— ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

# CSV í”„ë¡œì„¸ì„œ ì‚¬ìš© ì˜ˆì œ
print("\n=== CSV ê³ ê¸‰ ì²˜ë¦¬ ì˜ˆì œ ===")

# ìƒ˜í”Œ ì§ì› ë°ì´í„° ìƒì„±
employee_data = [
    ['name', 'age', 'department', 'salary', 'email'],
    ['ê¹€ì² ìˆ˜', '28', 'IT', '3500000', 'kim@company.com'],
    ['ì´ì˜í¬', '32', 'HR', '4000000', 'lee@company.com'],
    ['ë°•ë¯¼ìˆ˜', '', 'IT', '3200000', 'park@company.com'],  # ë‚˜ì´ ëˆ„ë½
    ['ìµœì§€ì›', '29', 'Sales', '3800000', 'choi-invalid-email'],  # ì˜ëª»ëœ ì´ë©”ì¼
    ['ì •í˜„ìš°', '35', 'IT', 'invalid', 'jung@company.com'],  # ì˜ëª»ëœ ê¸‰ì—¬
    ['í•œë¯¸ì˜', '27', 'Marketing', '3600000', 'han@company.com']
]

with open('employees.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerows(employee_data)

# CSV í”„ë¡œì„¸ì„œ ì‚¬ìš©
processor = CSVProcessor('employees.csv')

if processor.load_data():
    # ë°ì´í„° ê²€ì¦ ê·œì¹™ ì •ì˜
    validation_rules = {
        'name': {'required': True},
        'age': {'required': True, 'type': 'int', 'range': (18, 65)},
        'salary': {'required': True, 'type': 'int', 'range': (2000000, 10000000)},
        'email': {'required': True, 'type': 'email'}
    }
    
    # ë°ì´í„° ê²€ì¦
    errors = processor.validate_data(validation_rules)
    if errors:
        print("\në°ì´í„° ê²€ì¦ ì˜¤ë¥˜:")
        for error in errors:
            print(f"  â€¢ {error}")
    else:
        print("\nâœ“ ëª¨ë“  ë°ì´í„°ê°€ ìœ íš¨í•©ë‹ˆë‹¤.")
    
    # ë°ì´í„° í•„í„°ë§ (IT ë¶€ì„œ, ê¸‰ì—¬ 3500000 ì´ìƒ)
    filtered_data = processor.filter_data({
        'department': {'operator': '==', 'value': 'IT'},
        'salary': {'operator': '>=', 'value': 3500000}
    })
    
    print(f"\ní•„í„°ë§ ê²°ê³¼: {len(filtered_data)}ê°œì˜ ë ˆì½”ë“œ")
    for record in filtered_data:
        print(f"  {record['name']}: {record['department']}, {record['salary']}ì›")
    
    # í•„í„°ë§ëœ ë°ì´í„° ì €ì¥
    if filtered_data:
        processor.save_data(filtered_data, 'it_high_salary.csv')
```

## 7. ì—°ìŠµ ë¬¸ì œ

### ì—°ìŠµ 1: ë¡œê·¸ íŒŒì¼ ë¶„ì„ê¸°
ì›¹ ì„œë²„ ë¡œê·¸ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì ‘ê·¼ í†µê³„ë¥¼ ìƒì„±í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•˜ì„¸ìš”.

### ì—°ìŠµ 2: ì„¤ì • íŒŒì¼ ë³€í™˜ê¸°
INI í˜•ì‹ì˜ ì„¤ì • íŒŒì¼ì„ JSONì´ë‚˜ YAML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬ë¥¼ ë§Œë“œì„¸ìš”.

### ì—°ìŠµ 3: íŒŒì¼ ë°±ì—… ì‹œìŠ¤í…œ
ì§€ì •ëœ ë””ë ‰í† ë¦¬ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ë°±ì—…í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì„¸ìš”.

### ì—°ìŠµ 4: ë°ì´í„° í¬ë§· ë³€í™˜ê¸°
CSV íŒŒì¼ì„ JSONì´ë‚˜ XML í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•˜ì„¸ìš”.

## ì •ë¦¬

ì´ ì±•í„°ì—ì„œ í•™ìŠµí•œ ë‚´ìš©:

1. **JSON ì²˜ë¦¬**: íŒŒì´ì¬ ê°ì²´ì™€ JSON ê°„ì˜ ì§ë ¬í™”/ì—­ì§ë ¬í™”
2. **CSV ì²˜ë¦¬**: ì²´ê³„ì ì¸ ë°ì´í„° ë¶„ì„ê³¼ ì²˜ë¦¬ ê¸°ë²•
3. **XML ì²˜ë¦¬**: DOM ë°©ì‹ì˜ XML ë¬¸ì„œ ì¡°ì‘
4. **ë°”ì´ë„ˆë¦¬ íŒŒì¼**: êµ¬ì¡°í™”ëœ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì²˜ë¦¬
5. **ì••ì¶• íŒŒì¼**: ZIPê³¼ TAR í˜•ì‹ì˜ ì••ì¶•/í•´ì œ
6. **ì„¤ì • íŒŒì¼**: ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì„¤ì • ê´€ë¦¬ íŒ¨í„´

ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” ì •ê·œí‘œí˜„ì‹ì„ í™œìš©í•œ ê³ ê¸‰ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê¸°ë²•ì„ í•™ìŠµí•˜ê² ìŠµë‹ˆë‹¤.

### í•µì‹¬ í¬ì¸íŠ¸
- ë°ì´í„° í˜•ì‹ì— ë§ëŠ” ì ì ˆí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤
- ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ í†µí•œ ì•ˆì „í•œ íŒŒì¼ ì²˜ë¦¬ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ê³ ë ¤í•œ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ê¸°ë²•ì„ ìµí˜€ì•¼ í•©ë‹ˆë‹¤
- ì„¤ì • ê´€ë¦¬ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìœ ì§€ë³´ìˆ˜ì„±ì„ í¬ê²Œ ì¢Œìš°í•©ë‹ˆë‹¤
- ì••ì¶• íŒŒì¼ì€ ì €ì¥ ê³µê°„ê³¼ ì „ì†¡ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ì¤‘ìš”í•œ ë„êµ¬ì…ë‹ˆë‹¤
</rewritten_file> 