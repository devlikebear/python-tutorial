# Chapter 10: ë©€í‹°ìŠ¤ë ˆë”©ê³¼ ë¹„ë™ê¸° ì²˜ë¦¬ ê¸°ì´ˆ

## í•™ìŠµ ëª©í‘œ
ì´ ì±•í„°ë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- ë™ì‹œì„±ê³¼ ë³‘ë ¬ì„±ì˜ ê°œë…ê³¼ ì°¨ì´ì  ì´í•´í•˜ê¸°
- ìŠ¤ë ˆë”©ì„ í™œìš©í•œ ë™ì‹œ ì‘ì—… ì²˜ë¦¬í•˜ê¸°
- ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í†µí•œ ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„í•˜ê¸°
- asyncioë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ë§ˆìŠ¤í„°í•˜ê¸°
- ìŠ¤ë ˆë“œ ê°„ ë™ê¸°í™”ì™€ ë°ì´í„° ê³µìœ  ì²˜ë¦¬í•˜ê¸°
- ì ì ˆí•œ ë™ì‹œì„± íŒ¨í„´ ì„ íƒí•˜ê³  ì„±ëŠ¥ ìµœì í™”í•˜ê¸°
- GIL(Global Interpreter Lock)ì˜ ì˜í–¥ ì´í•´í•˜ê¸°

## 1. ë™ì‹œì„±ê³¼ ë³‘ë ¬ì„± ê¸°ì´ˆ

### 1.1 ê°œë… ì´í•´

```python
print("=== ë™ì‹œì„±ê³¼ ë³‘ë ¬ì„± ê¸°ì´ˆ ===")

import time
import threading
import multiprocessing
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

def demonstrate_concepts():
    """ë™ì‹œì„±ê³¼ ë³‘ë ¬ì„± ê°œë… ì„¤ëª…"""
    
    print("1. ë™ì‹œì„± vs ë³‘ë ¬ì„±:")
    print("  ë™ì‹œì„±(Concurrency): ì—¬ëŸ¬ ì‘ì—…ì„ ë²ˆê°ˆì•„ê°€ë©° ì²˜ë¦¬ (ë…¼ë¦¬ì ìœ¼ë¡œ ë™ì‹œ)")
    print("  ë³‘ë ¬ì„±(Parallelism): ì—¬ëŸ¬ ì‘ì—…ì„ ì‹¤ì œë¡œ ë™ì‹œì— ì²˜ë¦¬ (ë¬¼ë¦¬ì ìœ¼ë¡œ ë™ì‹œ)")
    print()
    
    print("2. Pythonì—ì„œì˜ ì„ íƒ ê¸°ì¤€:")
    print("  I/O ë°”ìš´ë“œ ì‘ì—…: ìŠ¤ë ˆë”© ë˜ëŠ” ë¹„ë™ê¸°")
    print("  CPU ë°”ìš´ë“œ ì‘ì—…: ë©€í‹°í”„ë¡œì„¸ì‹±")
    print("  ë‹¨ì¼ ìŠ¤ë ˆë“œ ë¹„ë™ê¸°: asyncio")

demonstrate_concepts()

# CPU ì§‘ì•½ì  ì‘ì—… ì˜ˆì œ
def cpu_intensive_task(n, task_id):
    """CPU ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜"""
    start_time = time.time()
    total = 0
    for i in range(n):
        total += i ** 2
    end_time = time.time()
    print(f"  ì‘ì—… {task_id}: {end_time - start_time:.2f}ì´ˆ, ê²°ê³¼: {total}")
    return total

# I/O ì§‘ì•½ì  ì‘ì—… ì˜ˆì œ
def io_intensive_task(duration, task_id):
    """I/O ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜"""
    start_time = time.time()
    time.sleep(duration)  # I/O ëŒ€ê¸° ì‹œë®¬ë ˆì´ì…˜
    end_time = time.time()
    print(f"  I/O ì‘ì—… {task_id}: {end_time - start_time:.2f}ì´ˆ ì™„ë£Œ")
    return f"ê²°ê³¼ {task_id}"

def sequential_execution():
    """ìˆœì°¨ ì‹¤í–‰ ì˜ˆì œ"""
    
    print(f"\n3. ìˆœì°¨ ì‹¤í–‰:")
    start_time = time.time()
    
    # CPU ì‘ì—…ë“¤
    for i in range(3):
        cpu_intensive_task(1000000, i+1)
    
    end_time = time.time()
    print(f"  ì´ ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")

sequential_execution()
```

### 1.2 Pythonì˜ GIL (Global Interpreter Lock)

```python
print("\n=== Pythonì˜ GIL ===")

def demonstrate_gil():
    """GILì˜ ì˜í–¥ ì„¤ëª…"""
    
    print("4. GIL (Global Interpreter Lock):")
    print("  - í•œ ë²ˆì— í•˜ë‚˜ì˜ ìŠ¤ë ˆë“œë§Œ Python ë°”ì´íŠ¸ì½”ë“œ ì‹¤í–‰ ê°€ëŠ¥")
    print("  - CPU ì§‘ì•½ì  ì‘ì—…ì—ì„œëŠ” ë©€í‹°ìŠ¤ë ˆë”© íš¨ê³¼ ì œí•œì ")
    print("  - I/O ì‘ì—… ì¤‘ì—ëŠ” GILì´ í•´ì œë˜ì–´ ìŠ¤ë ˆë”© íš¨ê³¼ì ")
    print("  - C í™•ì¥ ëª¨ë“ˆì—ì„œëŠ” GIL í•´ì œ ê°€ëŠ¥")
    print()
    
    print("5. ê° ë°©ì‹ì˜ íŠ¹ì§•:")
    print("  ìŠ¤ë ˆë”©: ë©”ëª¨ë¦¬ ê³µìœ , ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­ ë¹ ë¦„, GIL ì œì•½")
    print("  í”„ë¡œì„¸ì‹±: ë…ë¦½ì  ë©”ëª¨ë¦¬, ì§„ì •í•œ ë³‘ë ¬ì„±, ì˜¤ë²„í—¤ë“œ í¼")
    print("  ë¹„ë™ê¸°: ë‹¨ì¼ ìŠ¤ë ˆë“œ, ì´ë²¤íŠ¸ ë£¨í”„, I/O ìµœì í™”")

demonstrate_gil()

# GIL ì˜í–¥ í™•ì¸ ì‹¤í—˜
import threading
import time

def count_up(n):
    """ì¹´ìš´íŒ… ì‘ì—…"""
    for i in range(n):
        pass

def measure_threading_performance():
    """ìŠ¤ë ˆë”© ì„±ëŠ¥ ì¸¡ì •"""
    
    print(f"\n6. GIL ì˜í–¥ ì‹¤í—˜:")
    n = 50000000  # 5ì²œë§Œ ë²ˆ ë°˜ë³µ
    
    # ë‹¨ì¼ ìŠ¤ë ˆë“œ
    start_time = time.time()
    count_up(n)
    single_time = time.time() - start_time
    print(f"  ë‹¨ì¼ ìŠ¤ë ˆë“œ: {single_time:.2f}ì´ˆ")
    
    # ë©€í‹° ìŠ¤ë ˆë“œ (2ê°œ)
    start_time = time.time()
    
    thread1 = threading.Thread(target=count_up, args=(n//2,))
    thread2 = threading.Thread(target=count_up, args=(n//2,))
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    multi_time = time.time() - start_time
    print(f"  ë©€í‹° ìŠ¤ë ˆë“œ: {multi_time:.2f}ì´ˆ")
    print(f"  ì„±ëŠ¥ ë¹„ìœ¨: {single_time / multi_time:.2f}ë°°")
    
    if multi_time >= single_time:
        print("  â†’ GILë¡œ ì¸í•´ ë©€í‹°ìŠ¤ë ˆë”©ì´ ë” ëŠë¦¼")
    else:
        print("  â†’ ë©€í‹°ìŠ¤ë ˆë”©ì´ ë¹ ë¦„")

# ì•ˆì „í•œ í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰
try:
    measure_threading_performance()
except:
    print("  (ì„±ëŠ¥ ì¸¡ì •ì€ í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
```

## 2. ìŠ¤ë ˆë”© (Threading)

### 2.1 ê¸°ë³¸ ìŠ¤ë ˆë”©

```python
print("\n=== ìŠ¤ë ˆë”© ê¸°ì´ˆ ===")

import threading
import time
import queue

def worker_function(name, duration):
    """ì›Œì»¤ í•¨ìˆ˜"""
    print(f"  ìŠ¤ë ˆë“œ {name} ì‹œì‘")
    time.sleep(duration)
    print(f"  ìŠ¤ë ˆë“œ {name} ì™„ë£Œ ({duration}ì´ˆ)")
    return f"ê²°ê³¼ {name}"

def basic_threading():
    """ê¸°ë³¸ ìŠ¤ë ˆë”© ì‚¬ìš©ë²•"""
    
    print("1. ê¸°ë³¸ ìŠ¤ë ˆë“œ ìƒì„±ê³¼ ì‹¤í–‰:")
    
    # ìŠ¤ë ˆë“œ ìƒì„± ë°©ë²• 1: Thread í´ë˜ìŠ¤ ì§ì ‘ ì‚¬ìš©
    thread1 = threading.Thread(target=worker_function, args=("A", 1))
    thread2 = threading.Thread(target=worker_function, args=("B", 2))
    
    start_time = time.time()
    
    # ìŠ¤ë ˆë“œ ì‹œì‘
    thread1.start()
    thread2.start()
    
    # ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    thread1.join()
    thread2.join()
    
    end_time = time.time()
    print(f"  ì´ ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")

basic_threading()

class WorkerThread(threading.Thread):
    """ì»¤ìŠ¤í…€ ìŠ¤ë ˆë“œ í´ë˜ìŠ¤"""
    
    def __init__(self, name, task_queue, result_queue):
        super().__init__()
        self.name = name
        self.task_queue = task_queue
        self.result_queue = result_queue
        self.daemon = True  # ë©”ì¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ê°™ì´ ì¢…ë£Œ
    
    def run(self):
        """ìŠ¤ë ˆë“œ ì‹¤í–‰ ë©”ì„œë“œ"""
        while True:
            try:
                task = self.task_queue.get(timeout=1)
                if task is None:  # ì¢…ë£Œ ì‹ í˜¸
                    break
                
                # ì‘ì—… ì²˜ë¦¬
                print(f"  {self.name}: ì‘ì—… '{task}' ì²˜ë¦¬ ì¤‘...")
                time.sleep(0.5)  # ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
                result = f"{task}_ì™„ë£Œ"
                
                self.result_queue.put(result)
                self.task_queue.task_done()
                
            except queue.Empty:
                break
        
        print(f"  {self.name}: ì¢…ë£Œ")

def custom_thread_example():
    """ì»¤ìŠ¤í…€ ìŠ¤ë ˆë“œ í´ë˜ìŠ¤ ì‚¬ìš©"""
    
    print(f"\n2. ì»¤ìŠ¤í…€ ìŠ¤ë ˆë“œ í´ë˜ìŠ¤:")
    
    # í ìƒì„±
    task_queue = queue.Queue()
    result_queue = queue.Queue()
    
    # ì‘ì—… ì¶”ê°€
    tasks = ["ì‘ì—…1", "ì‘ì—…2", "ì‘ì—…3", "ì‘ì—…4", "ì‘ì—…5"]
    for task in tasks:
        task_queue.put(task)
    
    # ì›Œì»¤ ìŠ¤ë ˆë“œ ìƒì„±
    workers = []
    for i in range(3):
        worker = WorkerThread(f"ì›Œì»¤{i+1}", task_queue, result_queue)
        worker.start()
        workers.append(worker)
    
    # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    task_queue.join()
    
    # ì›Œì»¤ ì¢…ë£Œ
    for _ in workers:
        task_queue.put(None)
    
    for worker in workers:
        worker.join()
    
    # ê²°ê³¼ ìˆ˜ì§‘
    results = []
    while not result_queue.empty():
        results.append(result_queue.get())
    
    print(f"  ê²°ê³¼: {results}")

custom_thread_example()
```

### 2.2 ìŠ¤ë ˆë“œ ë™ê¸°í™”

```python
print("\n=== ìŠ¤ë ˆë“œ ë™ê¸°í™” ===")

import threading
import time
import random

# ê³µìœ  ìì›
shared_counter = 0
shared_list = []

def unsafe_increment(name, iterations):
    """ì•ˆì „í•˜ì§€ ì•Šì€ ì¹´ìš´í„° ì¦ê°€"""
    global shared_counter
    
    for i in range(iterations):
        # ì´ ë¶€ë¶„ì—ì„œ ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ë°œìƒ ê°€ëŠ¥
        temp = shared_counter
        temp += 1
        shared_counter = temp
    
    print(f"  {name}: {iterations}ë²ˆ ì¦ê°€ ì™„ë£Œ")

def demonstrate_race_condition():
    """ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ì‹œì—°"""
    
    print("3. ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ë¬¸ì œ:")
    
    global shared_counter
    shared_counter = 0
    
    # ë‘ ìŠ¤ë ˆë“œê°€ ë™ì‹œì— ì¹´ìš´í„° ì¦ê°€
    thread1 = threading.Thread(target=unsafe_increment, args=("ìŠ¤ë ˆë“œ1", 1000))
    thread2 = threading.Thread(target=unsafe_increment, args=("ìŠ¤ë ˆë“œ2", 1000))
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    print(f"  ì˜ˆìƒ ê²°ê³¼: 2000")
    print(f"  ì‹¤ì œ ê²°ê³¼: {shared_counter}")
    if shared_counter != 2000:
        print("  â†’ ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ë°œìƒ!")

demonstrate_race_condition()

# Lockì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ë²„ì „
counter_lock = threading.Lock()
safe_counter = 0

def safe_increment(name, iterations):
    """Lockì„ ì‚¬ìš©í•œ ì•ˆì „í•œ ì¹´ìš´í„° ì¦ê°€"""
    global safe_counter
    
    for i in range(iterations):
        with counter_lock:  # Lock íšë“
            temp = safe_counter
            temp += 1
            safe_counter = temp
    
    print(f"  {name}: {iterations}ë²ˆ ì•ˆì „í•˜ê²Œ ì¦ê°€ ì™„ë£Œ")

def demonstrate_lock():
    """Lockì„ ì‚¬ìš©í•œ ë™ê¸°í™”"""
    
    print(f"\n4. Lockì„ ì‚¬ìš©í•œ ë™ê¸°í™”:")
    
    global safe_counter
    safe_counter = 0
    
    thread1 = threading.Thread(target=safe_increment, args=("ì•ˆì „ìŠ¤ë ˆë“œ1", 1000))
    thread2 = threading.Thread(target=safe_increment, args=("ì•ˆì „ìŠ¤ë ˆë“œ2", 1000))
    
    thread1.start()
    thread2.start()
    
    thread1.join()
    thread2.join()
    
    print(f"  ì˜ˆìƒ ê²°ê³¼: 2000")
    print(f"  ì‹¤ì œ ê²°ê³¼: {safe_counter}")
    print("  â†’ Lockìœ¼ë¡œ ë™ê¸°í™” ì„±ê³µ!")

demonstrate_lock()

def demonstrate_other_sync_primitives():
    """ë‹¤ë¥¸ ë™ê¸°í™” í”„ë¦¬ë¯¸í‹°ë¸Œë“¤"""
    
    print(f"\n5. ë‹¤ë¥¸ ë™ê¸°í™” ë„êµ¬ë“¤:")
    
    # RLock (ì¬ê·€ ë½)
    rlock = threading.RLock()
    
    def recursive_function(depth):
        with rlock:
            print(f"    ì¬ê·€ ê¹Šì´: {depth}")
            if depth > 0:
                recursive_function(depth - 1)
    
    print("  RLock (ì¬ê·€ ë½) ì˜ˆì œ:")
    thread = threading.Thread(target=recursive_function, args=(3,))
    thread.start()
    thread.join()
    
    # Semaphore (ì„¸ë§ˆí¬ì–´)
    print(f"\n  Semaphore (ì„¸ë§ˆí¬ì–´) ì˜ˆì œ:")
    semaphore = threading.Semaphore(2)  # ìµœëŒ€ 2ê°œ ìŠ¤ë ˆë“œë§Œ ë™ì‹œ ì ‘ê·¼
    
    def limited_resource(name):
        with semaphore:
            print(f"    {name}: ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ì¤‘...")
            time.sleep(1)
            print(f"    {name}: ë¦¬ì†ŒìŠ¤ í•´ì œ")
    
    # 5ê°œ ìŠ¤ë ˆë“œê°€ ë™ì‹œì— ì‹œì‘í•˜ì§€ë§Œ 2ê°œì”©ë§Œ ì‹¤í–‰
    threads = []
    for i in range(5):
        t = threading.Thread(target=limited_resource, args=(f"ìŠ¤ë ˆë“œ{i+1}",))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    # Event (ì´ë²¤íŠ¸)
    print(f"\n  Event (ì´ë²¤íŠ¸) ì˜ˆì œ:")
    event = threading.Event()
    
    def waiter(name):
        print(f"    {name}: ì´ë²¤íŠ¸ ëŒ€ê¸° ì¤‘...")
        event.wait()
        print(f"    {name}: ì´ë²¤íŠ¸ ìˆ˜ì‹ , ì‘ì—… ì‹œì‘!")
    
    def setter():
        time.sleep(2)
        print(f"    ì´ë²¤íŠ¸ ë°œìƒ!")
        event.set()
    
    # ëŒ€ê¸° ìŠ¤ë ˆë“œë“¤
    for i in range(3):
        t = threading.Thread(target=waiter, args=(f"ëŒ€ê¸°ì{i+1}",))
        t.start()
    
    # ì´ë²¤íŠ¸ ì„¤ì • ìŠ¤ë ˆë“œ
    threading.Thread(target=setter).start()
    time.sleep(3)  # ê²°ê³¼ í™•ì¸ì„ ìœ„í•œ ëŒ€ê¸°

demonstrate_other_sync_primitives()
```

### 2.3 ìŠ¤ë ˆë“œ í’€

```python
print("\n=== ìŠ¤ë ˆë“œ í’€ ===")

from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import time

def download_simulation(url_id):
    """ë‹¤ìš´ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜"""
    # ì‹¤ì œë¡œëŠ” requestsë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    download_time = random.uniform(0.5, 2.0)
    time.sleep(download_time)
    
    result = {
        'url_id': url_id,
        'download_time': download_time,
        'size': random.randint(1000, 5000)
    }
    
    print(f"  ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: URL {url_id} ({download_time:.2f}ì´ˆ)")
    return result

def thread_pool_example():
    """ìŠ¤ë ˆë“œ í’€ ì‚¬ìš© ì˜ˆì œ"""
    
    print("6. ThreadPoolExecutor ì‚¬ìš©:")
    
    urls = [f"url_{i}" for i in range(1, 6)]
    
    # ìˆœì°¨ ì²˜ë¦¬
    print(f"  ìˆœì°¨ ì²˜ë¦¬:")
    start_time = time.time()
    sequential_results = []
    for url in urls:
        result = download_simulation(url)
        sequential_results.append(result)
    sequential_time = time.time() - start_time
    print(f"    ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„: {sequential_time:.2f}ì´ˆ")
    
    # ìŠ¤ë ˆë“œ í’€ ì²˜ë¦¬
    print(f"\n  ìŠ¤ë ˆë“œ í’€ ì²˜ë¦¬:")
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=3) as executor:
        # ë°©ë²• 1: map ì‚¬ìš©
        results = list(executor.map(download_simulation, urls))
    
    pool_time = time.time() - start_time
    print(f"    ìŠ¤ë ˆë“œ í’€ ì²˜ë¦¬ ì‹œê°„: {pool_time:.2f}ì´ˆ")
    print(f"    ì„±ëŠ¥ í–¥ìƒ: {sequential_time / pool_time:.2f}ë°°")

thread_pool_example()

def advanced_thread_pool():
    """ê³ ê¸‰ ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©ë²•"""
    
    print(f"\n7. ê³ ê¸‰ ìŠ¤ë ˆë“œ í’€ íŒ¨í„´:")
    
    def process_task(task_id):
        """ì‘ì—… ì²˜ë¦¬"""
        processing_time = random.uniform(1, 3)
        time.sleep(processing_time)
        
        # ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
        if random.random() < 0.2:  # 20% í™•ë¥ ë¡œ ì‹¤íŒ¨
            raise Exception(f"ì‘ì—… {task_id} ì‹¤íŒ¨")
        
        return f"ì‘ì—… {task_id} ì„±ê³µ ({processing_time:.2f}ì´ˆ)"
    
    tasks = list(range(1, 8))
    
    with ThreadPoolExecutor(max_workers=3) as executor:
        # ë°©ë²• 2: submitê³¼ as_completed ì‚¬ìš©
        future_to_task = {executor.submit(process_task, task): task for task in tasks}
        
        print(f"  ì‹¤ì‹œê°„ ê²°ê³¼ ì²˜ë¦¬:")
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            try:
                result = future.result()
                print(f"    âœ“ {result}")
            except Exception as exc:
                print(f"    âœ— ì‘ì—… {task}: {exc}")

advanced_thread_pool()
```

## 3. ë©€í‹°í”„ë¡œì„¸ì‹± (Multiprocessing)

### 3.1 ê¸°ë³¸ í”„ë¡œì„¸ì‹±

```python
print("\n=== ë©€í‹°í”„ë¡œì„¸ì‹± ê¸°ì´ˆ ===")

import multiprocessing
import time
import os

def cpu_bound_task(n, process_id):
    """CPU ì§‘ì•½ì  ì‘ì—…"""
    start_time = time.time()
    result = sum(i * i for i in range(n))
    end_time = time.time()
    
    print(f"  í”„ë¡œì„¸ìŠ¤ {process_id} (PID: {os.getpid()}): "
          f"{end_time - start_time:.2f}ì´ˆ, ê²°ê³¼: {result}")
    return result

def basic_multiprocessing():
    """ê¸°ë³¸ ë©€í‹°í”„ë¡œì„¸ì‹±"""
    
    print("8. ê¸°ë³¸ í”„ë¡œì„¸ìŠ¤ ìƒì„±:")
    print(f"  ë©”ì¸ í”„ë¡œì„¸ìŠ¤ PID: {os.getpid()}")
    
    # í”„ë¡œì„¸ìŠ¤ ìƒì„±
    processes = []
    start_time = time.time()
    
    for i in range(2):
        p = multiprocessing.Process(
            target=cpu_bound_task, 
            args=(2000000, i+1)
        )
        processes.append(p)
        p.start()
    
    # ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
    for p in processes:
        p.join()
    
    end_time = time.time()
    print(f"  ì´ ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")

# multiprocessing ëª¨ë“ˆì€ ë©”ì¸ ëª¨ë“ˆì—ì„œë§Œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨
if __name__ == '__main__':
    try:
        basic_multiprocessing()
    except:
        print("  (ì¼ë¶€ í™˜ê²½ì—ì„œëŠ” ë©€í‹°í”„ë¡œì„¸ì‹±ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

def demonstrate_process_communication():
    """í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ """
    
    print(f"\n9. í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ :")
    
    def worker_with_queue(queue, process_id):
        """íë¥¼ ì‚¬ìš©í•˜ëŠ” ì›Œì»¤"""
        for i in range(3):
            item = f"í”„ë¡œì„¸ìŠ¤{process_id}_í•­ëª©{i+1}"
            queue.put(item)
            print(f"  í”„ë¡œì„¸ìŠ¤ {process_id}: {item} ìƒì„±")
            time.sleep(0.5)
    
    def consumer(queue):
        """íì—ì„œ ì†Œë¹„í•˜ëŠ” í”„ë¡œì„¸ìŠ¤"""
        items = []
        while True:
            try:
                item = queue.get(timeout=2)
                items.append(item)
                print(f"  ì†Œë¹„ì: {item} ìˆ˜ì‹ ")
            except:
                break
        return items
    
    try:
        # í ìƒì„±
        queue = multiprocessing.Queue()
        
        # ìƒì‚°ì í”„ë¡œì„¸ìŠ¤ë“¤
        producers = []
        for i in range(2):
            p = multiprocessing.Process(
                target=worker_with_queue, 
                args=(queue, i+1)
            )
            producers.append(p)
            p.start()
        
        # ìƒì‚°ì ì™„ë£Œ ëŒ€ê¸°
        for p in producers:
            p.join()
        
        # ì†Œë¹„ìì—ì„œ ê²°ê³¼ ìˆ˜ì§‘
        results = consumer(queue)
        print(f"  ìˆ˜ì§‘ëœ í•­ëª©ë“¤: {results}")
        
    except:
        print("  (í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹  ì˜ˆì œëŠ” í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

demonstrate_process_communication()
```

### 3.2 í”„ë¡œì„¸ìŠ¤ í’€

```python
print("\n=== í”„ë¡œì„¸ìŠ¤ í’€ ===")

from concurrent.futures import ProcessPoolExecutor
import multiprocessing

def cpu_intensive_calculation(n):
    """CPU ì§‘ì•½ì  ê³„ì‚°"""
    return sum(i * i for i in range(n))

def process_pool_example():
    """í”„ë¡œì„¸ìŠ¤ í’€ ì‚¬ìš© ì˜ˆì œ"""
    
    print("10. ProcessPoolExecutor ì‚¬ìš©:")
    
    numbers = [1000000, 1500000, 2000000, 2500000]
    
    # ìˆœì°¨ ì²˜ë¦¬
    print(f"  ìˆœì°¨ ì²˜ë¦¬:")
    start_time = time.time()
    sequential_results = [cpu_intensive_calculation(n) for n in numbers]
    sequential_time = time.time() - start_time
    print(f"    ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„: {sequential_time:.2f}ì´ˆ")
    
    # í”„ë¡œì„¸ìŠ¤ í’€ ì²˜ë¦¬
    print(f"  í”„ë¡œì„¸ìŠ¤ í’€ ì²˜ë¦¬:")
    try:
        start_time = time.time()
        
        with ProcessPoolExecutor(max_workers=2) as executor:
            parallel_results = list(executor.map(cpu_intensive_calculation, numbers))
        
        parallel_time = time.time() - start_time
        print(f"    í”„ë¡œì„¸ìŠ¤ í’€ ì²˜ë¦¬ ì‹œê°„: {parallel_time:.2f}ì´ˆ")
        print(f"    ì„±ëŠ¥ í–¥ìƒ: {sequential_time / parallel_time:.2f}ë°°")
        
        # ê²°ê³¼ ê²€ì¦
        if sequential_results == parallel_results:
            print(f"    âœ“ ê²°ê³¼ ì¼ì¹˜ í™•ì¸")
        
    except:
        print("    (í”„ë¡œì„¸ìŠ¤ í’€ì€ ì¼ë¶€ í™˜ê²½ì—ì„œ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

process_pool_example()

def shared_memory_example():
    """ê³µìœ  ë©”ëª¨ë¦¬ ì‚¬ìš©"""
    
    print(f"\n11. ê³µìœ  ë©”ëª¨ë¦¬:")
    
    def increment_shared_value(shared_val, lock, process_id):
        """ê³µìœ  ê°’ ì¦ê°€"""
        for i in range(5):
            with lock:
                temp = shared_val.value
                temp += 1
                shared_val.value = temp
                print(f"  í”„ë¡œì„¸ìŠ¤ {process_id}: ê°’ì„ {shared_val.value}ë¡œ ì¦ê°€")
                time.sleep(0.1)
    
    try:
        # ê³µìœ  ë³€ìˆ˜ì™€ ë½ ìƒì„±
        shared_value = multiprocessing.Value('i', 0)  # ì •ìˆ˜í˜• ê³µìœ  ë³€ìˆ˜
        lock = multiprocessing.Lock()
        
        # í”„ë¡œì„¸ìŠ¤ë“¤ ìƒì„±
        processes = []
        for i in range(2):
            p = multiprocessing.Process(
                target=increment_shared_value,
                args=(shared_value, lock, i+1)
            )
            processes.append(p)
            p.start()
        
        # ì™„ë£Œ ëŒ€ê¸°
        for p in processes:
            p.join()
        
        print(f"  ìµœì¢… ê°’: {shared_value.value}")
        
    except:
        print("  (ê³µìœ  ë©”ëª¨ë¦¬ ì˜ˆì œëŠ” í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

shared_memory_example()
```

## 4. ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° (Asyncio)

### 4.1 ê¸°ë³¸ ë¹„ë™ê¸° ê°œë…

```python
print("\n=== ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆ ===")

import asyncio
import time
import aiohttp
import random

async def async_task(name, duration):
    """ë¹„ë™ê¸° ì‘ì—…"""
    print(f"  {name} ì‹œì‘")
    await asyncio.sleep(duration)  # ë¹„ë™ê¸° ëŒ€ê¸°
    print(f"  {name} ì™„ë£Œ ({duration}ì´ˆ)")
    return f"ê²°ê³¼_{name}"

async def basic_async_example():
    """ê¸°ë³¸ ë¹„ë™ê¸° ì˜ˆì œ"""
    
    print("12. ê¸°ë³¸ ë¹„ë™ê¸° ì‹¤í–‰:")
    
    # ìˆœì°¨ ì‹¤í–‰
    start_time = time.time()
    result1 = await async_task("ì‘ì—…1", 1)
    result2 = await async_task("ì‘ì—…2", 2)
    sequential_time = time.time() - start_time
    print(f"    ìˆœì°¨ ì‹¤í–‰ ì‹œê°„: {sequential_time:.2f}ì´ˆ")
    
    # ë™ì‹œ ì‹¤í–‰
    print(f"\n  ë™ì‹œ ì‹¤í–‰:")
    start_time = time.time()
    
    # ë°©ë²• 1: gather ì‚¬ìš©
    results = await asyncio.gather(
        async_task("ë™ì‹œì‘ì—…1", 1),
        async_task("ë™ì‹œì‘ì—…2", 2),
        async_task("ë™ì‹œì‘ì—…3", 1.5)
    )
    
    concurrent_time = time.time() - start_time
    print(f"    ë™ì‹œ ì‹¤í–‰ ì‹œê°„: {concurrent_time:.2f}ì´ˆ")
    print(f"    ì„±ëŠ¥ í–¥ìƒ: {sequential_time / concurrent_time:.2f}ë°°")
    print(f"    ê²°ê³¼: {results}")

# ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
def run_async_example():
    """ë¹„ë™ê¸° ì˜ˆì œ ì‹¤í–‰"""
    try:
        asyncio.run(basic_async_example())
    except Exception as e:
        print(f"  ë¹„ë™ê¸° ì‹¤í–‰ ì˜¤ë¥˜: {e}")

run_async_example()

async def task_management_example():
    """íƒœìŠ¤í¬ ê´€ë¦¬ ì˜ˆì œ"""
    
    print(f"\n13. íƒœìŠ¤í¬ ê´€ë¦¬:")
    
    async def long_running_task(task_id):
        """ì¥ì‹œê°„ ì‹¤í–‰ ì‘ì—…"""
        try:
            for i in range(5):
                print(f"    ì‘ì—… {task_id}: ì§„í–‰ {i+1}/5")
                await asyncio.sleep(0.5)
            return f"ì‘ì—… {task_id} ì™„ë£Œ"
        except asyncio.CancelledError:
            print(f"    ì‘ì—… {task_id} ì·¨ì†Œë¨")
            raise
    
    # íƒœìŠ¤í¬ ìƒì„±
    task1 = asyncio.create_task(long_running_task("A"))
    task2 = asyncio.create_task(long_running_task("B"))
    
    # ì¼ì • ì‹œê°„ í›„ íƒœìŠ¤í¬ ì·¨ì†Œ
    await asyncio.sleep(1.5)
    task2.cancel()
    
    # ê²°ê³¼ ìˆ˜ì§‘
    try:
        result1 = await task1
        print(f"  {result1}")
    except:
        print(f"  ì‘ì—… A ì‹¤íŒ¨")
    
    try:
        result2 = await task2
        print(f"  {result2}")
    except asyncio.CancelledError:
        print(f"  ì‘ì—… Bê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")

def run_task_management():
    """íƒœìŠ¤í¬ ê´€ë¦¬ ì˜ˆì œ ì‹¤í–‰"""
    try:
        asyncio.run(task_management_example())
    except:
        print("  (íƒœìŠ¤í¬ ê´€ë¦¬ ì˜ˆì œëŠ” í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

run_task_management()
```

### 4.2 ë¹„ë™ê¸° I/O íŒ¨í„´

```python
print("\n=== ë¹„ë™ê¸° I/O íŒ¨í„´ ===")

async def simulate_api_call(api_id, delay):
    """API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜"""
    print(f"  API {api_id} í˜¸ì¶œ ì‹œì‘")
    await asyncio.sleep(delay)  # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    
    # ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
    if random.random() < 0.2:  # 20% í™•ë¥ ë¡œ ì‹¤íŒ¨
        raise Exception(f"API {api_id} í˜¸ì¶œ ì‹¤íŒ¨")
    
    result = {
        'api_id': api_id,
        'data': f"ì‘ë‹µë°ì´í„°_{api_id}",
        'delay': delay
    }
    print(f"  API {api_id} í˜¸ì¶œ ì™„ë£Œ")
    return result

async def async_io_patterns():
    """ë¹„ë™ê¸° I/O íŒ¨í„´ë“¤"""
    
    print("14. ë¹„ë™ê¸° I/O íŒ¨í„´:")
    
    # íŒ¨í„´ 1: as_completed - ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
    print(f"  íŒ¨í„´ 1: as_completed")
    
    tasks = [
        simulate_api_call(f"API{i}", random.uniform(0.5, 2.0))
        for i in range(1, 5)
    ]
    
    async for completed_task in asyncio.as_completed(tasks):
        try:
            result = await completed_task
            print(f"    ì™„ë£Œ: {result['api_id']} ({result['delay']:.2f}ì´ˆ)")
        except Exception as e:
            print(f"    ì˜¤ë¥˜: {e}")
    
    # íŒ¨í„´ 2: wait - ì¡°ê±´ë¶€ ëŒ€ê¸°
    print(f"\n  íŒ¨í„´ 2: wait with timeout")
    
    tasks = [
        asyncio.create_task(simulate_api_call(f"API{i}", random.uniform(1, 3)))
        for i in range(5, 8)
    ]
    
    try:
        done, pending = await asyncio.wait(tasks, timeout=2.0)
        
        print(f"    ì™„ë£Œëœ ì‘ì—…: {len(done)}ê°œ")
        for task in done:
            try:
                result = await task
                print(f"      ì™„ë£Œ: {result['api_id']}")
            except Exception as e:
                print(f"      ì˜¤ë¥˜: {e}")
        
        print(f"    ë¯¸ì™„ë£Œ ì‘ì—…: {len(pending)}ê°œ")
        for task in pending:
            task.cancel()
            print(f"      ì·¨ì†Œë¨")
        
    except asyncio.TimeoutError:
        print(f"    íƒ€ì„ì•„ì›ƒ ë°œìƒ")

def run_async_io_patterns():
    """ë¹„ë™ê¸° I/O íŒ¨í„´ ì‹¤í–‰"""
    try:
        asyncio.run(async_io_patterns())
    except:
        print("  (ë¹„ë™ê¸° I/O íŒ¨í„´ì€ í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

run_async_io_patterns()

async def producer_consumer_pattern():
    """ë¹„ë™ê¸° ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´"""
    
    print(f"\n15. ë¹„ë™ê¸° ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´:")
    
    async def producer(queue, producer_id):
        """ë¹„ë™ê¸° ìƒì‚°ì"""
        for i in range(3):
            item = f"ìƒì‚°ì{producer_id}_í•­ëª©{i+1}"
            await queue.put(item)
            print(f"  ìƒì‚°: {item}")
            await asyncio.sleep(0.5)
        
        await queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸
        print(f"  ìƒì‚°ì {producer_id} ì™„ë£Œ")
    
    async def consumer(queue, consumer_id):
        """ë¹„ë™ê¸° ì†Œë¹„ì"""
        consumed_items = []
        while True:
            item = await queue.get()
            if item is None:
                queue.task_done()
                break
            
            consumed_items.append(item)
            print(f"  ì†Œë¹„ {consumer_id}: {item}")
            await asyncio.sleep(0.3)
            queue.task_done()
        
        print(f"  ì†Œë¹„ì {consumer_id} ì™„ë£Œ: {len(consumed_items)}ê°œ ì²˜ë¦¬")
        return consumed_items
    
    # í ìƒì„±
    queue = asyncio.Queue(maxsize=5)
    
    # ìƒì‚°ìì™€ ì†Œë¹„ì ì‹¤í–‰
    await asyncio.gather(
        producer(queue, 1),
        consumer(queue, 1),
        producer(queue, 2),
        consumer(queue, 2)
    )

def run_producer_consumer():
    """ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´ ì‹¤í–‰"""
    try:
        asyncio.run(producer_consumer_pattern())
    except:
        print("  (ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´ì€ í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

run_producer_consumer()
```

### 4.3 ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €

```python
print("\n=== ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ===")

class AsyncResource:
    """ë¹„ë™ê¸° ë¦¬ì†ŒìŠ¤ ë§¤ë‹ˆì €"""
    
    def __init__(self, name):
        self.name = name
        self.is_open = False
    
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì§„ì…"""
        print(f"  {self.name} ë¦¬ì†ŒìŠ¤ ì—´ê¸° ì‹œì‘...")
        await asyncio.sleep(0.5)  # ë¦¬ì†ŒìŠ¤ ì—´ê¸° ì‹œë®¬ë ˆì´ì…˜
        self.is_open = True
        print(f"  {self.name} ë¦¬ì†ŒìŠ¤ ì¤€ë¹„ ì™„ë£Œ")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì¢…ë£Œ"""
        print(f"  {self.name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
        await asyncio.sleep(0.3)  # ì •ë¦¬ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        self.is_open = False
        print(f"  {self.name} ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
        if exc_type:
            print(f"  ì˜ˆì™¸ ë°œìƒ: {exc_type.__name__}: {exc_val}")
            return False  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´
    
    async def do_work(self):
        """ì‘ì—… ìˆ˜í–‰"""
        if not self.is_open:
            raise RuntimeError("ë¦¬ì†ŒìŠ¤ê°€ ì—´ë ¤ìˆì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        print(f"  {self.name}ì—ì„œ ì‘ì—… ìˆ˜í–‰ ì¤‘...")
        await asyncio.sleep(1)
        print(f"  {self.name} ì‘ì—… ì™„ë£Œ")
        return f"{self.name} ê²°ê³¼"

async def async_context_manager_example():
    """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©"""
    
    print("16. ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €:")
    
    # ì •ìƒì ì¸ ì‚¬ìš©
    async with AsyncResource("ë°ì´í„°ë² ì´ìŠ¤") as db:
        result = await db.do_work()
        print(f"  ì‘ì—… ê²°ê³¼: {result}")
    
    print()
    
    # ì˜ˆì™¸ ë°œìƒ ì‹œ
    try:
        async with AsyncResource("ë„¤íŠ¸ì›Œí¬") as network:
            await network.do_work()
            raise ValueError("ì˜ë„ì  ì˜ˆì™¸")
    except ValueError as e:
        print(f"  ì˜ˆì™¸ ì²˜ë¦¬ë¨: {e}")

def run_async_context_manager():
    """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‹¤í–‰"""
    try:
        asyncio.run(async_context_manager_example())
    except:
        print("  (ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ëŠ” í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

run_async_context_manager()
```

## 5. ì„±ëŠ¥ ë¹„êµì™€ ì„ íƒ ê¸°ì¤€

### 5.1 ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥ ë¹„êµ

```python
print("\n=== ì„±ëŠ¥ ë¹„êµì™€ ì„ íƒ ê¸°ì¤€ ===")

import time
import threading
import multiprocessing
import asyncio
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor

def io_bound_sync(task_id, duration):
    """I/O ë°”ìš´ë“œ ë™ê¸° ì‘ì—…"""
    time.sleep(duration)
    return f"IOì‘ì—…{task_id}_ì™„ë£Œ"

async def io_bound_async(task_id, duration):
    """I/O ë°”ìš´ë“œ ë¹„ë™ê¸° ì‘ì—…"""
    await asyncio.sleep(duration)
    return f"ë¹„ë™ê¸°IOì‘ì—…{task_id}_ì™„ë£Œ"

def cpu_bound_sync(n):
    """CPU ë°”ìš´ë“œ ë™ê¸° ì‘ì—…"""
    return sum(i * i for i in range(n))

def performance_comparison():
    """ì„±ëŠ¥ ë¹„êµ"""
    
    print("17. I/O ë°”ìš´ë“œ ì‘ì—… ì„±ëŠ¥ ë¹„êµ:")
    
    tasks = [(i, 0.5) for i in range(1, 6)]  # 5ê°œ ì‘ì—…, ê°ê° 0.5ì´ˆ
    
    # 1. ìˆœì°¨ ì‹¤í–‰
    start_time = time.time()
    sequential_results = [io_bound_sync(task_id, duration) for task_id, duration in tasks]
    sequential_time = time.time() - start_time
    print(f"  ìˆœì°¨ ì‹¤í–‰: {sequential_time:.2f}ì´ˆ")
    
    # 2. ìŠ¤ë ˆë“œ í’€
    start_time = time.time()
    with ThreadPoolExecutor(max_workers=3) as executor:
        thread_results = list(executor.map(lambda x: io_bound_sync(*x), tasks))
    thread_time = time.time() - start_time
    print(f"  ìŠ¤ë ˆë“œ í’€: {thread_time:.2f}ì´ˆ (í–¥ìƒ: {sequential_time/thread_time:.2f}ë°°)")
    
    # 3. ë¹„ë™ê¸° ì‹¤í–‰
    async def async_test():
        start_time = time.time()
        async_results = await asyncio.gather(
            *[io_bound_async(task_id, duration) for task_id, duration in tasks]
        )
        return time.time() - start_time, async_results
    
    try:
        async_time, async_results = asyncio.run(async_test())
        print(f"  ë¹„ë™ê¸° ì‹¤í–‰: {async_time:.2f}ì´ˆ (í–¥ìƒ: {sequential_time/async_time:.2f}ë°°)")
    except:
        print(f"  ë¹„ë™ê¸° ì‹¤í–‰: (í™˜ê²½ ì œí•œ)")

performance_comparison()

def cpu_bound_comparison():
    """CPU ë°”ìš´ë“œ ì‘ì—… ë¹„êµ"""
    
    print(f"\n18. CPU ë°”ìš´ë“œ ì‘ì—… ì„±ëŠ¥ ë¹„êµ:")
    
    tasks = [2000000] * 4  # 4ê°œì˜ ë™ì¼í•œ CPU ì‘ì—…
    
    # 1. ìˆœì°¨ ì‹¤í–‰
    start_time = time.time()
    sequential_results = [cpu_bound_sync(n) for n in tasks]
    sequential_time = time.time() - start_time
    print(f"  ìˆœì°¨ ì‹¤í–‰: {sequential_time:.2f}ì´ˆ")
    
    # 2. ìŠ¤ë ˆë“œ í’€ (GILë¡œ ì¸í•´ íš¨ê³¼ ì œí•œì )
    start_time = time.time()
    with ThreadPoolExecutor(max_workers=4) as executor:
        thread_results = list(executor.map(cpu_bound_sync, tasks))
    thread_time = time.time() - start_time
    print(f"  ìŠ¤ë ˆë“œ í’€: {thread_time:.2f}ì´ˆ (ë¹„ìœ¨: {thread_time/sequential_time:.2f})")
    
    # 3. í”„ë¡œì„¸ìŠ¤ í’€
    try:
        start_time = time.time()
        with ProcessPoolExecutor(max_workers=2) as executor:
            process_results = list(executor.map(cpu_bound_sync, tasks))
        process_time = time.time() - start_time
        print(f"  í”„ë¡œì„¸ìŠ¤ í’€: {process_time:.2f}ì´ˆ (í–¥ìƒ: {sequential_time/process_time:.2f}ë°°)")
    except:
        print(f"  í”„ë¡œì„¸ìŠ¤ í’€: (í™˜ê²½ ì œí•œ)")

cpu_bound_comparison()

def selection_guidelines():
    """ì„ íƒ ê°€ì´ë“œë¼ì¸"""
    
    print(f"\n19. ë™ì‹œì„± íŒ¨í„´ ì„ íƒ ê°€ì´ë“œë¼ì¸:")
    
    guidelines = {
        "I/O ë°”ìš´ë“œ + ê°„ë‹¨í•œ ë¡œì§": {
            "ì¶”ì²œ": "ìŠ¤ë ˆë”© ë˜ëŠ” ë¹„ë™ê¸°",
            "ì´ìœ ": "I/O ëŒ€ê¸° ì‹œê°„ ë™ì•ˆ ë‹¤ë¥¸ ì‘ì—… ìˆ˜í–‰ ê°€ëŠ¥",
            "ì˜ˆì‹œ": "íŒŒì¼ ì½ê¸°/ì“°ê¸°, ë„¤íŠ¸ì›Œí¬ ìš”ì²­, ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬"
        },
        "I/O ë°”ìš´ë“œ + ë³µì¡í•œ ë¡œì§": {
            "ì¶”ì²œ": "ë¹„ë™ê¸° (asyncio)",
            "ì´ìœ ": "ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥, ë©”ëª¨ë¦¬ íš¨ìœ¨ì ",
            "ì˜ˆì‹œ": "ì›¹ ìŠ¤í¬ë˜í•‘, API ì„œë²„, ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬"
        },
        "CPU ë°”ìš´ë“œ": {
            "ì¶”ì²œ": "ë©€í‹°í”„ë¡œì„¸ì‹±",
            "ì´ìœ ": "GIL ìš°íšŒí•˜ì—¬ ì§„ì •í•œ ë³‘ë ¬ ì²˜ë¦¬",
            "ì˜ˆì‹œ": "ìˆ˜í•™ ê³„ì‚°, ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì²˜ë¦¬, ì•”í˜¸í™”"
        },
        "í˜¼í•© ì‘ì—…": {
            "ì¶”ì²œ": "ìƒí™©ì— ë”°ë¼ ì¡°í•©",
            "ì´ìœ ": "ê° ì‘ì—… ìœ í˜•ì— ìµœì í™”ëœ ë°©ì‹ ì‚¬ìš©",
            "ì˜ˆì‹œ": "ë°ì´í„° ìˆ˜ì§‘(ë¹„ë™ê¸°) + ë¶„ì„(í”„ë¡œì„¸ì‹±)"
        }
    }
    
    for scenario, info in guidelines.items():
        print(f"  {scenario}:")
        print(f"    ì¶”ì²œ: {info['ì¶”ì²œ']}")
        print(f"    ì´ìœ : {info['ì´ìœ ']}")
        print(f"    ì˜ˆì‹œ: {info['ì˜ˆì‹œ']}")
        print()

selection_guidelines()

def resource_usage_comparison():
    """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë¹„êµ"""
    
    print(f"20. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ íŠ¹ì„±:")
    
    characteristics = {
        "ìŠ¤ë ˆë”©": {
            "ë©”ëª¨ë¦¬": "ê³µìœ  (ì ìŒ)",
            "ìƒì„± ë¹„ìš©": "ì¤‘ê°„",
            "ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­": "ë¹ ë¦„",
            "í™•ì¥ì„±": "ì œí•œì  (ìˆ˜ë°± ê°œ)",
            "ë””ë²„ê¹…": "ì–´ë ¤ì›€ (ë ˆì´ìŠ¤ ì»¨ë””ì…˜)"
        },
        "í”„ë¡œì„¸ì‹±": {
            "ë©”ëª¨ë¦¬": "ë…ë¦½ì  (ë§ìŒ)",
            "ìƒì„± ë¹„ìš©": "ë†’ìŒ",
            "ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­": "ëŠë¦¼",
            "í™•ì¥ì„±": "CPU ì½”ì–´ ìˆ˜ì— ì˜ì¡´",
            "ë””ë²„ê¹…": "ìƒëŒ€ì ìœ¼ë¡œ ì‰¬ì›€"
        },
        "ë¹„ë™ê¸°": {
            "ë©”ëª¨ë¦¬": "ë‹¨ì¼ ìŠ¤ë ˆë“œ (ì ìŒ)",
            "ìƒì„± ë¹„ìš©": "ë‚®ìŒ",
            "ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­": "ì—†ìŒ (í˜‘ë ¥ì )",
            "í™•ì¥ì„±": "ë§¤ìš° ë†’ìŒ (ìˆ˜ë§Œ ê°œ)",
            "ë””ë²„ê¹…": "ì¤‘ê°„ (ì½œë°± ì§€ì˜¥ ì£¼ì˜)"
        }
    }
    
    for method, chars in characteristics.items():
        print(f"  {method}:")
        for aspect, value in chars.items():
            print(f"    {aspect}: {value}")
        print()

resource_usage_comparison()
```

## 6. ì‹¤ìš©ì ì¸ í™œìš© ì˜ˆì œ

### 6.1 ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œìŠ¤í…œ

```python
print("\n=== ì‹¤ìš©ì ì¸ í™œìš© ì˜ˆì œ ===")

import asyncio
import time
import random
from dataclasses import dataclass
from typing import List, Dict, Any

@dataclass
class ScrapingResult:
    """ìŠ¤í¬ë˜í•‘ ê²°ê³¼"""
    url: str
    status: str
    data: Dict[str, Any]
    processing_time: float

def simulate_web_request(url: str) -> ScrapingResult:
    """ì›¹ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜"""
    start_time = time.time()
    
    # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    delay = random.uniform(0.5, 2.0)
    time.sleep(delay)
    
    # ì„±ê³µ/ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
    if random.random() < 0.1:  # 10% ì‹¤íŒ¨ìœ¨
        status = "failed"
        data = {"error": "Connection timeout"}
    else:
        status = "success"
        data = {
            "title": f"Title for {url}",
            "content_length": random.randint(1000, 5000),
            "links": random.randint(10, 50)
        }
    
    processing_time = time.time() - start_time
    return ScrapingResult(url, status, data, processing_time)

async def simulate_async_web_request(url: str) -> ScrapingResult:
    """ë¹„ë™ê¸° ì›¹ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜"""
    start_time = time.time()
    
    # ë¹„ë™ê¸° ë„¤íŠ¸ì›Œí¬ ì§€ì—°
    delay = random.uniform(0.5, 2.0)
    await asyncio.sleep(delay)
    
    if random.random() < 0.1:
        status = "failed"
        data = {"error": "Connection timeout"}
    else:
        status = "success"
        data = {
            "title": f"Async Title for {url}",
            "content_length": random.randint(1000, 5000),
            "links": random.randint(10, 50)
        }
    
    processing_time = time.time() - start_time
    return ScrapingResult(url, status, data, processing_time)

def web_scraping_comparison():
    """ì›¹ ìŠ¤í¬ë˜í•‘ ë°©ì‹ ë¹„êµ"""
    
    print("21. ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œìŠ¤í…œ ë¹„êµ:")
    
    urls = [f"https://example{i}.com" for i in range(1, 11)]
    
    # 1. ìˆœì°¨ ìŠ¤í¬ë˜í•‘
    print(f"  ìˆœì°¨ ìŠ¤í¬ë˜í•‘:")
    start_time = time.time()
    sequential_results = []
    for url in urls:
        result = simulate_web_request(url)
        sequential_results.append(result)
    sequential_time = time.time() - start_time
    
    success_count = sum(1 for r in sequential_results if r.status == "success")
    print(f"    ì‹œê°„: {sequential_time:.2f}ì´ˆ")
    print(f"    ì„±ê³µ: {success_count}/{len(urls)}")
    
    # 2. ìŠ¤ë ˆë“œ í’€ ìŠ¤í¬ë˜í•‘
    print(f"\n  ìŠ¤ë ˆë“œ í’€ ìŠ¤í¬ë˜í•‘:")
    start_time = time.time()
    with ThreadPoolExecutor(max_workers=5) as executor:
        thread_results = list(executor.map(simulate_web_request, urls))
    thread_time = time.time() - start_time
    
    success_count = sum(1 for r in thread_results if r.status == "success")
    print(f"    ì‹œê°„: {thread_time:.2f}ì´ˆ (í–¥ìƒ: {sequential_time/thread_time:.2f}ë°°)")
    print(f"    ì„±ê³µ: {success_count}/{len(urls)}")
    
    # 3. ë¹„ë™ê¸° ìŠ¤í¬ë˜í•‘
    async def async_scraping():
        start_time = time.time()
        async_results = await asyncio.gather(
            *[simulate_async_web_request(url) for url in urls],
            return_exceptions=True
        )
        return time.time() - start_time, async_results
    
    try:
        async_time, async_results = asyncio.run(async_scraping())
        success_count = sum(1 for r in async_results if isinstance(r, ScrapingResult) and r.status == "success")
        print(f"\n  ë¹„ë™ê¸° ìŠ¤í¬ë˜í•‘:")
        print(f"    ì‹œê°„: {async_time:.2f}ì´ˆ (í–¥ìƒ: {sequential_time/async_time:.2f}ë°°)")
        print(f"    ì„±ê³µ: {success_count}/{len(urls)}")
    except:
        print(f"\n  ë¹„ë™ê¸° ìŠ¤í¬ë˜í•‘: (í™˜ê²½ ì œí•œ)")

web_scraping_comparison()
```

### 6.2 ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
print("\n=== ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ===")

import queue
import threading
import time
from typing import Generator, List

class DataProcessor:
    """ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, num_workers: int = 3):
        self.num_workers = num_workers
        self.input_queue = queue.Queue()
        self.output_queue = queue.Queue()
        self.workers = []
        self.running = False
    
    def worker(self, worker_id: int):
        """ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                data = self.input_queue.get(timeout=1)
                if data is None:  # ì¢…ë£Œ ì‹ í˜¸
                    break
                
                # ë°ì´í„° ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                processed_data = self.process_data(data, worker_id)
                self.output_queue.put(processed_data)
                self.input_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"    ì›Œì»¤ {worker_id} ì˜¤ë¥˜: {e}")
    
    def process_data(self, data: Dict[str, Any], worker_id: int) -> Dict[str, Any]:
        """ë°ì´í„° ì²˜ë¦¬ ë¡œì§"""
        # ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        processing_time = random.uniform(0.1, 0.5)
        time.sleep(processing_time)
        
        return {
            'original': data,
            'processed_by': f'worker_{worker_id}',
            'processing_time': processing_time,
            'processed_at': time.time(),
            'value': data.get('value', 0) * 2  # ê°„ë‹¨í•œ ë³€í™˜
        }
    
    def start(self):
        """íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        self.running = True
        for i in range(self.num_workers):
            worker = threading.Thread(target=self.worker, args=(i+1,))
            worker.start()
            self.workers.append(worker)
        print(f"    íŒŒì´í”„ë¼ì¸ ì‹œì‘: {self.num_workers}ê°œ ì›Œì»¤")
    
    def stop(self):
        """íŒŒì´í”„ë¼ì¸ ì •ì§€"""
        self.running = False
        
        # ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
        for _ in self.workers:
            self.input_queue.put(None)
        
        # ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
        for worker in self.workers:
            worker.join()
        
        print(f"    íŒŒì´í”„ë¼ì¸ ì •ì§€")
    
    def add_data(self, data: Dict[str, Any]):
        """ë°ì´í„° ì¶”ê°€"""
        self.input_queue.put(data)
    
    def get_results(self) -> List[Dict[str, Any]]:
        """ê²°ê³¼ ìˆ˜ì§‘"""
        results = []
        while not self.output_queue.empty():
            results.append(self.output_queue.get())
        return results

def data_pipeline_example():
    """ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜ˆì œ"""
    
    print("22. ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:")
    
    # íŒŒì´í”„ë¼ì¸ ìƒì„± ë° ì‹œì‘
    processor = DataProcessor(num_workers=3)
    processor.start()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = [
        {'id': i, 'value': random.randint(1, 100)}
        for i in range(1, 16)
    ]
    
    print(f"    {len(test_data)}ê°œ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    start_time = time.time()
    
    # ë°ì´í„° ì¶”ê°€
    for data in test_data:
        processor.add_data(data)
    
    # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    processor.input_queue.join()
    
    # ê²°ê³¼ ìˆ˜ì§‘
    results = processor.get_results()
    processing_time = time.time() - start_time
    
    print(f"    ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
    print(f"    ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
    print(f"    í‰ê·  ì²˜ë¦¬ ì‹œê°„: {processing_time/len(results):.3f}ì´ˆ/ê±´")
    
    # íŒŒì´í”„ë¼ì¸ ì •ì§€
    processor.stop()
    
    # ê²°ê³¼ ë¶„ì„
    if results:
        worker_stats = {}
        for result in results:
            worker = result['processed_by']
            worker_stats[worker] = worker_stats.get(worker, 0) + 1
        
        print(f"    ì›Œì»¤ë³„ ì²˜ë¦¬ëŸ‰: {worker_stats}")

data_pipeline_example()
```

### 6.3 ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

```python
print("\n=== ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ===")

import asyncio
import time
import random
from collections import deque
from dataclasses import dataclass
from typing import Deque, Dict, List

@dataclass
class MetricData:
    """ë©”íŠ¸ë¦­ ë°ì´í„°"""
    timestamp: float
    metric_name: str
    value: float
    source: str

class MonitoringSystem:
    """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.metrics_buffer: Deque[MetricData] = deque(maxsize=1000)
        self.alerts: List[str] = []
        self.running = False
        self.stats = {
            'total_metrics': 0,
            'alerts_triggered': 0,
            'sources': set()
        }
    
    async def metric_collector(self, source: str, interval: float):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
        while self.running:
            # ì‹œë®¬ë ˆì´ì…˜ëœ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            metrics = [
                MetricData(
                    timestamp=time.time(),
                    metric_name=metric_type,
                    value=self.generate_metric_value(metric_type),
                    source=source
                )
                for metric_type in ['cpu_usage', 'memory_usage', 'disk_io']
            ]
            
            for metric in metrics:
                self.metrics_buffer.append(metric)
                self.stats['total_metrics'] += 1
                self.stats['sources'].add(source)
            
            await asyncio.sleep(interval)
    
    def generate_metric_value(self, metric_type: str) -> float:
        """ë©”íŠ¸ë¦­ ê°’ ìƒì„±"""
        base_values = {
            'cpu_usage': 30.0,
            'memory_usage': 50.0,
            'disk_io': 20.0
        }
        
        base = base_values.get(metric_type, 50.0)
        # ì •ìƒ ë²”ìœ„ì—ì„œ ë³€ë™
        return max(0, base + random.uniform(-20, 20))
    
    async def alert_processor(self):
        """ì•Œë¦¼ ì²˜ë¦¬ê¸°"""
        alert_thresholds = {
            'cpu_usage': 80.0,
            'memory_usage': 85.0,
            'disk_io': 70.0
        }
        
        while self.running:
            # ìµœê·¼ ë©”íŠ¸ë¦­ í™•ì¸
            recent_metrics = list(self.metrics_buffer)[-10:]  # ìµœê·¼ 10ê°œ
            
            for metric in recent_metrics:
                threshold = alert_thresholds.get(metric.metric_name)
                if threshold and metric.value > threshold:
                    alert_msg = (f"ALERT: {metric.source}ì˜ {metric.metric_name} "
                               f"{metric.value:.1f}% (ì„ê³„ê°’: {threshold}%)")
                    self.alerts.append(alert_msg)
                    self.stats['alerts_triggered'] += 1
                    print(f"    ğŸš¨ {alert_msg}")
            
            await asyncio.sleep(2.0)  # 2ì´ˆë§ˆë‹¤ í™•ì¸
    
    async def stats_reporter(self):
        """í†µê³„ ë¦¬í¬í„°"""
        while self.running:
            await asyncio.sleep(5.0)  # 5ì´ˆë§ˆë‹¤ ë¦¬í¬íŠ¸
            
            print(f"    ğŸ“Š í†µê³„ ë¦¬í¬íŠ¸:")
            print(f"      ì´ ë©”íŠ¸ë¦­: {self.stats['total_metrics']}")
            print(f"      ì•Œë¦¼ ë°œìƒ: {self.stats['alerts_triggered']}")
            print(f"      ëª¨ë‹ˆí„°ë§ ì†ŒìŠ¤: {len(self.stats['sources'])}ê°œ")
            
            if self.metrics_buffer:
                recent = list(self.metrics_buffer)[-5:]
                print(f"      ìµœê·¼ ë©”íŠ¸ë¦­ (5ê°œ):")
                for metric in recent:
                    print(f"        {metric.source}.{metric.metric_name}: {metric.value:.1f}")
    
    async def run_monitoring(self, duration: float = 10.0):
        """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        self.running = True
        
        print(f"    ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹œì‘ ({duration}ì´ˆ ë™ì•ˆ)")
        
        # ë‹¤ì¤‘ ì†ŒìŠ¤ì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        collectors = [
            self.metric_collector("server1", 1.0),
            self.metric_collector("server2", 1.5),
            self.metric_collector("database", 2.0),
        ]
        
        # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ë™ì‹œ ì‹¤í–‰
        await asyncio.wait_for(
            asyncio.gather(
                *collectors,
                self.alert_processor(),
                self.stats_reporter()
            ),
            timeout=duration
        )

async def monitoring_system_example():
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì˜ˆì œ"""
    
    print("23. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ:")
    
    system = MonitoringSystem()
    
    try:
        await system.run_monitoring(duration=8.0)
    except asyncio.TimeoutError:
        system.running = False
        print(f"    ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¢…ë£Œ")
        
        # ìµœì¢… í†µê³„
        print(f"\n    ìµœì¢… í†µê³„:")
        print(f"      ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­: {system.stats['total_metrics']}ê°œ")
        print(f"      ë°œìƒí•œ ì•Œë¦¼: {system.stats['alerts_triggered']}ê°œ")
        print(f"      ëª¨ë‹ˆí„°ë§ ì†ŒìŠ¤: {list(system.stats['sources'])}")

def run_monitoring_example():
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹¤í–‰"""
    try:
        asyncio.run(monitoring_system_example())
    except:
        print("    (ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì€ í™˜ê²½ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

run_monitoring_example()
```

## 7. ì—°ìŠµ ë¬¸ì œ

### ì—°ìŠµ 1: ë‹¤ìš´ë¡œë“œ ë§¤ë‹ˆì €
ë©€í‹°ìŠ¤ë ˆë”©ì„ í™œìš©í•œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§¤ë‹ˆì €ë¥¼ êµ¬í˜„í•˜ì„¸ìš”. ì§„í–‰ë¥  í‘œì‹œ, ì¬ì‹œë„ ë¡œì§, ë™ì‹œ ë‹¤ìš´ë¡œë“œ ìˆ˜ ì œí•œ ê¸°ëŠ¥ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

### ì—°ìŠµ 2: ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸
ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•˜ì„¸ìš”. ë°ì´í„° ë¶„í• , ë³‘ë ¬ ì²˜ë¦¬, ê²°ê³¼ ë³‘í•© ê¸°ëŠ¥ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

### ì—°ìŠµ 3: ì›¹ API í´ë¼ì´ì–¸íŠ¸
asyncioë¥¼ í™œìš©í•œ ë¹„ë™ê¸° ì›¹ API í´ë¼ì´ì–¸íŠ¸ë¥¼ êµ¬í˜„í•˜ì„¸ìš”. ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ…, ì¬ì‹œë„, ë°°ì¹˜ ì²˜ë¦¬ ê¸°ëŠ¥ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

### ì—°ìŠµ 4: ì‹¤ì‹œê°„ ì±„íŒ… ì„œë²„
ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì„ í™œìš©í•œ ê°„ë‹¨í•œ ì±„íŒ… ì„œë²„ë¥¼ êµ¬í˜„í•˜ì„¸ìš”. ë‹¤ì¤‘ í´ë¼ì´ì–¸íŠ¸ ì§€ì›, ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŒ…, ì—°ê²° ê´€ë¦¬ ê¸°ëŠ¥ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

## ì •ë¦¬

ì´ ì±•í„°ì—ì„œ í•™ìŠµí•œ ë‚´ìš©:

1. **ë™ì‹œì„±ê³¼ ë³‘ë ¬ì„±**: ê°œë…ì˜ ì°¨ì´ì™€ Pythonì—ì„œì˜ êµ¬í˜„ ë°©ë²•
2. **ìŠ¤ë ˆë”©**: ê¸°ë³¸ ì‚¬ìš©ë²•, ë™ê¸°í™”, ìŠ¤ë ˆë“œ í’€ í™œìš©
3. **ë©€í‹°í”„ë¡œì„¸ì‹±**: í”„ë¡œì„¸ìŠ¤ ìƒì„±, í†µì‹ , í”„ë¡œì„¸ìŠ¤ í’€ ì‚¬ìš©
4. **ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°**: asyncioë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ I/O ì²˜ë¦¬
5. **GILì˜ ì˜í–¥**: Pythonì˜ íŠ¹ì„±ê³¼ ì ì ˆí•œ íŒ¨í„´ ì„ íƒ
6. **ì„±ëŠ¥ ìµœì í™”**: ì‘ì—… ìœ í˜•ì— ë”°ë¥¸ ìµœì  ë°©ì‹ ì„ íƒ
7. **ì‹¤ë¬´ í™œìš©**: ì›¹ ìŠ¤í¬ë˜í•‘, ë°ì´í„° ì²˜ë¦¬, ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

ë‹¤ìŒ ì±•í„°ì—ì„œëŠ” í…ŒìŠ¤íŒ…ê³¼ ë””ë²„ê¹…ì— ëŒ€í•´ í•™ìŠµí•˜ì—¬ ì•ˆì •ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì½”ë“œ ì‘ì„± ë°©ë²•ì„ ë°°ìš°ê² ìŠµë‹ˆë‹¤.

### í•µì‹¬ í¬ì¸íŠ¸
- I/O ë°”ìš´ë“œ ì‘ì—…ì—ëŠ” ìŠ¤ë ˆë”©ì´ë‚˜ ë¹„ë™ê¸°ê°€ íš¨ê³¼ì ì…ë‹ˆë‹¤
- CPU ë°”ìš´ë“œ ì‘ì—…ì—ëŠ” ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
- GILë¡œ ì¸í•´ Pythonì—ì„œ ë©€í‹°ìŠ¤ë ˆë”©ì€ CPU ì‘ì—…ì— ì œí•œì ì…ë‹ˆë‹¤
- ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì€ ë†’ì€ ë™ì‹œì„±ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì ì ˆí•œ ë™ê¸°í™” ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë ˆì´ìŠ¤ ì»¨ë””ì…˜ì„ ë°©ì§€í•´ì•¼ í•©ë‹ˆë‹¤
- ì„±ëŠ¥ ì¸¡ì •ì„ í†µí•´ ìµœì ì˜ ë™ì‹œì„± íŒ¨í„´ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤
- ì‹¤ë¬´ì—ì„œëŠ” ì‘ì—…ì˜ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë°©ì‹ì„ ì¡°í•©í•´ì•¼ í•©ë‹ˆë‹¤